# LLM 및 AI 에이전트 교육 커리큘럼

## 1. 대규모 언어 모델(LLM) 소개

대규모 언어 모델(Large Language Model, LLM)은 방대한 양의 텍스트 데이터를 학습하여 인간의 언어를 이해하고 생성할 수 있는 인공지능 모델입니다. 이 모델들은 자연어 처리(NLP) 분야에서 혁신을 일으키고 있으며, 다음과 같은 특징을 가지고 있습니다:

대규모 데이터 학습: LLM은 수십억 개의 매개변수(파라미터)를 가지고 있으며, 인터넷에서 수집된 방대한 양의 텍스트 데이터로 학습됩니다.
자기지도 학습: 대부분의 LLM은 레이블이 없는 데이터를 사용하여 자기지도 학습 방식으로 훈련됩니다. 예를 들어, 문장의 일부를 가리고 모델이 이를 예측하도록 하는 방식입니다.
전이 학습: 사전 학습된 LLM은 다양한 자연어 처리 작업에 적용될 수 있으며, 특정 작업에 대해 추가로 미세 조정될 수 있습니다.
다양한 응용: LLM은 텍스트 생성, 번역, 요약, 질문 답변 등 다양한 언어 관련 작업을 수행할 수 있습니다.

### 1.1. 초기 언어 모델 (1990년대 ~ 2000년대 초반)

**모델**: n-gram 모델과 같은 통계적 언어 모델

**개요**: 이전 단어들의 빈도를 기반으로 다음 단어를 예측하는 간단한 모델입니다.

**이유**:

-   컴퓨팅 파워의 한계로 간단한 통계적 접근법이 선호되었습니다.
-   대규모 디지털 텍스트 데이터의 부족으로 복잡한 모델 학습이 어려웠습니다.
-   이 모델들은 구현이 비교적 쉽고 해석이 용이했습니다.

### 1.2. 신경망 기반 모델 (2010년대 초반)

**모델**: 순환 신경망(RNN), 장단기 메모리(LSTM) 네트워크

**개요**: 순차적 데이터를 처리하며 이전 정보를 기억할 수 있는 신경망 구조입니다.

**이유**:

-   컴퓨팅 성능의 향상으로 더 복잡한 모델 학습이 가능해졌습니다.
-   대규모 디지털 텍스트 데이터의 가용성이 증가했습니다.
-   RNN과 LSTM은 시퀀스 데이터 처리에 효과적이어서 언어의 시간적 의존성을 잘 포착할 수 있었습니다.
-   그러나 장거리 의존성 학습의 한계와 병렬 처리의 어려움이 있었습니다.

### 1.3. 트랜스포머의 등장 (2017년)

**모델**: Transformer 아키텍처

**개요**: 어텐션 메커니즘을 사용하여 입력 시퀀스의 모든 부분을 동시에 고려할 수 있는 구조입니다.

**이유**:

-   어텐션 메커니즘을 통해 장거리 의존성 문제를 효과적으로 해결했습니다.
-   병렬 처리가 가능해져 학습 속도와 효율성이 크게 향상되었습니다.
-   인코더-디코더 구조로 다양한 NLP 작업에 유연하게 적용할 수 있었습니다.
-   단방향 : 이전에 생성된 토큰에 의존 (i am a \*\*\*)

### 1.4. BERT와 GPT의 출현 (2018년)

**모델**: BERT(Google), GPT(OpenAI)

**개요**: 트랜스포머를 기반으로 한 대규모 사전 학습 모델로, BERT는 양방향, GPT는 단방향 학습을 수행합니다.

**이유**:

-   트랜스포머 아키텍처를 기반으로 한 대규모 사전 학습의 효과가 입증되었습니다.
-   BERT의 양방향 학습은 문맥 이해 능력을 크게 향상시켰습니다.
-   GPT의 자기회귀 학습은 자연스러운 텍스트 생성을 가능하게 했습니다.
-   전이 학습을 통해 다양한 하위 작업에 쉽게 적용할 수 있었습니다.
-   양방향 : 무작위로 마스킹된 단어를 예측 ("The \*\*\* is bright today")

### 1.5. 대규모화 (2020년 이후)

**모델**: GPT-3, T5, PaLM 등

**개요**: 수천억 개의 매개변수를 가진 초대형 언어 모델로, 다양한 작업을 거의 인간 수준으로 수행할 수 있습니다.

**이유**:

-   대규모 컴퓨팅 인프라의 발전으로 초대형 모델 학습이 가능해졌습니다.
-   더 많은 매개변수와 더 큰 데이터셋으로 학습함으로써 모델의 성능이 비약적으로 향상되었습니다.
-   모델 크기 증가에 따른 능력의 창발(emergence)이 관찰되었습니다. 즉, 특정 규모를 넘어서면 예상치 못한 새로운 능력이 나타났습니다.
-   소수의 예시만으로도 다양한 작업을 수행할 수 있는 퓨샷 학습(few-shot learning) 능력이 향상되었습니다.

## 2. LLM의 작동 원리

### 2.1 토큰화 (Tokenization):

입력 텍스트를 작은 단위(토큰)로 나눕니다.
예: "안녕하세요" → ["안녕", "하세요"]
이해를 돕기 위한 설명: 문장을 단어나 의미 있는 부분으로 쪼개는 과정입니다.

### 2.2 임베딩 (Embedding):

각 토큰을 고차원 벡터로 변환합니다.
예: "안녕" → [0.1, 0.3, -0.2, ...]
간단한 설명: 각 단어를 컴퓨터가 이해할 수 있는 숫자 리스트로 바꾸는 과정입니다.

### 2.3 셀프 어텐션 (Self-Attention):

각 토큰이 다른 모든 토큰과 어떻게 관련되는지 계산합니다.
예: "나는 사과를 먹었다"에서 "먹었다"는 "사과"와 높은 관련성을 가집니다.
쉬운 설명: 문장 내의 각 단어가 다른 단어들과 얼마나 중요하게 연결되는지 파악하는 과정입니다.

### 2.4 피드 포워드 네트워크 (Feed-Forward Network):

각 토큰의 표현을 더욱 풍부하게 만듭니다.
간단한 설명: 각 단어의 의미를 더 깊이 있게 해석하는 과정입니다.

### 2.5 층 쌓기 (Stacking Layers):

위의 과정을 여러 번 반복하여 깊은 이해를 얻습니다.
쉬운 설명: 글을 여러 번 읽으면서 점점 더 깊이 있게 이해하는 것과 비슷합니다.

### 2.6 출력 생성 (Output Generation):

마지막 층의 결과를 사용하여 다음 토큰을 예측하거나 원하는 출력을 생성합니다.
예: 질문에 대한 답변, 문장 완성 등
간단한 설명: 이해한 내용을 바탕으로 적절한 응답을 만들어내는 과정입니다.

## 3. LLM 파인 튜닝

### 3.1. 파인 튜닝 이해하기

파인 튜닝은 사전 학습된 대규모 언어 모델을 특정 작업이나 도메인에 맞게 추가로 학습시키는 과정입니다.

-   전이 학습의 한 형태: 기존 지식을 새로운 작업에 적용합니다.
-   효율성: 처음부터 학습하는 것보다 시간과 자원을 절약합니다.
-   성능 향상: 특정 작업에 대해 모델의 성능을 크게 개선할 수 있습니다.
-   적은 데이터로도 가능: 대규모 사전 학습 모델의 지식을 활용하므로 상대적으로 적은 데이터로도 효과적입니다.

### 3.2. 파인 튜닝 기법

#### 3.2.1. 전체 파인 튜닝 (Full Fine-tuning)

-   모든 모델 파라미터를 업데이트합니다.
-   가장 일반적인 방법입니다.

##### 주요 사용 시기

-   충분한 계산 자원이 있을 때
-   대규모의 타겟 데이터셋이 있을 때
-   소스 작업과 타겟 작업이 상당히 다를 때

##### 장점

-   가장 높은 성능 향상 가능성
-   모델의 모든 부분을 타겟 작업에 최적화

##### 단점

-   높은 계산 비용
-   많은 저장 공간 필요
-   과적합 위험이 높음

#### 3.2.2. 부분 파인 튜닝 (Partial Fine-tuning)

-   모델의 일부 층만 업데이트합니다.
-   주로 상위 층을 튜닝하며, 하위 층은 고정합니다.

##### 주요 사용 시기

-   계산 자원이 제한적일 때
-   소스 작업과 타겟 작업이 유사할 때
-   적은 양의 타겟 데이터만 있을 때

##### 장점

-   전체 파인 튜닝보다 효율적
-   과적합 위험 감소
-   더 빠른 학습과 적은 메모리 사용

##### 단점

-   전체 파인 튜닝에 비해 성능 향상이 제한적일 수 있음
-   어떤 층을 튜닝할지 결정하는 것이 어려울 수 있음

#### 3.2.3. 어댑터 튜닝 (Adapter Tuning)

-   모델 구조에 작은 어댑터 층을 추가하고 이를 학습합니다.
-   원본 모델 파라미터는 변경하지 않습니다.

##### 주요 사용 시기

-   여러 작업을 하나의 모델로 처리해야 할 때
-   모델 크기를 최소화해야 할 때
-   빠른 적응이 필요한 경우

##### 장점

-   매우 효율적인 파라미터 사용
-   여러 작업을 위한 어댑터를 쉽게 전환 가능
-   원본 모델 보존

##### 단점

-   구현이 복잡할 수 있음
-   전체 파인 튜닝에 비해 성능이 약간 떨어질 수 있음

#### 3.2.4. 프롬프트 튜닝 (Prompt Tuning)

-   입력 프롬프트를 최적화하여 모델의 출력을 조정합니다.
-   모델 파라미터는 변경하지 않습니다.

##### 주요 사용 시기

-   모델 파라미터를 변경할 수 없을 때
-   빠른 작업 전환이 필요할 때
-   제로샷 또는 퓨샷 학습 시나리오에서

##### 장점

-   매우 적은 추가 파라미터만 필요
-   모델 자체를 변경하지 않아 유연성이 높음
-   여러 작업 간 빠른 전환 가능

##### 단점

-   복잡한 작업에서는 성능이 제한적일 수 있음
-   효과적인 프롬프트 설계가 어려울 수 있음

#### 3.2.5. LoRA (Low-Rank Adaptation)

-   저차원 업데이트를 통해 모델을 효율적으로 튜닝합니다.

##### 주요 사용 시기

-   대규모 모델을 효율적으로 튜닝해야 할 때
-   저장 공간과 계산 자원이 제한적일 때
-   빠른 작업 전환이 필요한 경우

##### 장점

-   매우 효율적인 파라미터 사용
-   빠른 학습과 적은 메모리 사용
-   원본 모델과 거의 동등한 성능 달성 가능

##### 단점

-   구현이 복잡할 수 있음
-   모든 작업에 동일하게 효과적이지 않을 수 있음

### 3.3. 파인 튜닝 과정

### 3.4. 파인 튜닝된 모델 평가

#### 정확도 (Accuracy)

설명: 전체 예측 중 올바르게 예측한 비율
목적: 모델의 전반적인 성능을 빠르게 파악하는 데 사용
공식: (True Positives + True Negatives) / Total Predictions

#### 정밀도 (Precision)

-   설명: 양성으로 예측한 것 중 실제 양성인 비율
-   목적: 거짓 양성(False Positive)을 최소화해야 할 때 중요
-   공식: True Positives / (True Positives + False Positives)

#### 재현율 (Recall)

-   설명: 실제 양성 중 양성으로 예측한 비율
-   목적: 거짓 음성(False Negative)을 최소화해야 할 때 중요
-   공식: True Positives / (True Positives + False Negatives)

#### F1 점수

-   설명: 정밀도와 재현율의 조화평균
-   목적: 정밀도와 재현율 사이의 균형을 평가할 때 사용
-   공식: 2 _ (Precision _ Recall) / (Precision + Recall)

#### 혼동 행렬 (Confusion Matrix)

-   설명: 예측 결과와 실제 값의 관계를 표로 나타낸 것
-   목적: 모델의 예측 패턴을 시각적으로 파악하고, 오류 유형을 분석

#### ROC 곡선 및 AUC

-   설명: 다양한 분류 임계값에서의 True Positive Rate와 False Positive Rate의 관계를 나타내는 곡선
-   목적: 모델의 분류 성능을 종합적으로 평가하고, 다른 모델과 비교하는 데 사용
-   AUC (Area Under the Curve): ROC 곡선 아래 면적으로, 1에 가까울수록 좋은 성능

#### 오류 분석

-   설명: 모델이 잘못 예측한 사례들을 자세히 살펴보는 과정
-   목적: 모델의 약점을 파악하고, 개선 방향을 찾는 데 사용
