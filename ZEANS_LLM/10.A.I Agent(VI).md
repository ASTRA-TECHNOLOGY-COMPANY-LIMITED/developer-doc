# Mẹo phát triển A.I Agent

## Mục lục

1. [Quản lý trạng thái (State) hiệu quả](#quản-lý-trạng-thái-state-hiệu-quả)
    - [Tầm quan trọng của quản lý trạng thái nhẹ](#tầm-quan-trọng-của-quản-lý-trạng-thái-nhẹ)
2. [Kỹ thuật Prompt](#kỹ-thuật-prompt)
    - [Cấu trúc hóa chỉ dẫn rõ ràng](#cấu-trúc-hóa-chỉ-dẫn-rõ-ràng)
    - [Thiết kế prompt dựa trên vai trò](#thiết-kế-prompt-dựa-trên-vai-trò)
    - [Tối ưu hóa cửa sổ ngữ cảnh](#tối-ưu-hóa-cửa-sổ-ngữ-cảnh)
    - [Mẫu prompt và biến hóa](#mẫu-prompt-và-biến-hóa)
3. [Chiến lược sử dụng RAG](#chiến-lược-sử-dụng-rag)
    - [Agentic RAG](#agentic-rag)
        - [Khái niệm cốt lõi](#khái-niệm-cốt-lõi)
        - [Ví dụ triển khai](#ví-dụ-triển-khai)
    - [Adaptive RAG](#adaptive-rag)
        - [Khái niệm cốt lõi](#khái-niệm-cốt-lõi-1)
        - [Ví dụ triển khai](#ví-dụ-triển-khai-1)
    - [Collaborative RAG (CRAG)](#collaborative-rag-crag)
        - [Khái niệm cốt lõi](#khái-niệm-cốt-lõi-2)
        - [Ví dụ triển khai](#ví-dụ-triển-khai-2)
    - [Self-RAG](#self-rag)
        - [Khái niệm cốt lõi](#khái-niệm-cốt-lõi-3)
        - [Ví dụ triển khai](#ví-dụ-triển-khai-3)
4. [Mẫu Plan & Execute](#mẫu-plan--execute)
    - [Khái niệm cốt lõi](#khái-niệm-cốt-lõi-4)
    - [Ưu điểm](#ưu-điểm)
    - [Ví dụ triển khai](#ví-dụ-triển-khai-4)
    - [Mẹo sử dụng](#mẹo-sử-dụng)

## 1. Quản lý trạng thái hiệu quả

Một trong những cân nhắc quan trọng nhất khi phát triển A.I Agent là quản lý trạng thái (State). Hãy tìm hiểu cách triển khai agent hiệu quả bằng cách tối thiểu hóa việc sử dụng bộ nhớ.

### 1.1. Tầm quan trọng của quản lý trạng thái nhẹ

A.I Agent cần ghi nhớ nhiều thông tin khác nhau trong quá trình thực hiện nhiệm vụ. Tuy nhiên, nếu lưu trữ tất cả thông tin dưới dạng trạng thái, sẽ gặp phải các vấn đề sau:

-   Tăng sử dụng bộ nhớ
-   Giảm tốc độ xử lý
-   Tăng chi phí (đặc biệt khi sử dụng mô hình dựa trên token)
-   Hạn chế khả năng mở rộng

Do đó, việc quản lý trạng thái một cách nhẹ nhàng là rất quan trọng. Một số chiến lược để thực hiện điều này:

1. **Chỉ lưu trữ thông tin cần thiết**: Chỉ lưu trữ thông tin thực sự cần thiết cho agent thực hiện nhiệm vụ.
2. **Sử dụng kỹ thuật tóm tắt**: Thay vì lưu trữ toàn bộ lịch sử hội thoại hoặc nội dung tài liệu, chỉ duy trì bản tóm tắt chính.
3. **Tận dụng lưu trữ bên ngoài**: Không quản lý tất cả thông tin dưới dạng trạng thái, mà sử dụng cơ sở dữ liệu hoặc hệ thống tệp bên ngoài khi cần.
4. **Thiết lập TTL (Time-To-Live)**: Các thông tin trạng thái cũ sẽ tự động bị xóa.
5. **Cập nhật trạng thái gia tăng**: Thay vì tính toán lại toàn bộ trạng thái, chỉ cập nhật phần thay đổi.

Bằng cách quản lý trạng thái hiệu quả, có thể cải thiện hiệu suất của A.I Agent và tối ưu hóa việc sử dụng tài nguyên.

## 2. Kỹ thuật Prompt

Hiệu suất của A.I Agent phụ thuộc nhiều vào thiết kế prompt. Có thể cải thiện đáng kể hiệu suất của agent thông qua kỹ thuật prompt hiệu quả.

### 2.1. Cấu trúc hóa chỉ dẫn rõ ràng

Prompt cung cấp cho agent phải có hình thức rõ ràng và có cấu trúc:

-   Xác định rõ mục tiêu và ràng buộc
-   Cung cấp hướng dẫn từng bước
-   Chỉ định rõ định dạng đầu ra mong muốn
-   Giải thích cách xử lý điều kiện biên và ngoại lệ

### 2.2. Thiết kế prompt dựa trên vai trò

Gán cho agent một vai trò cụ thể có thể giúp nhận được phản hồi nhất quán hơn:

1. **Gán vai trò chuyên gia**: "Bạn là chuyên gia toán học" hoặc "Bạn là kỹ sư phần mềm giàu kinh nghiệm"
2. **Sử dụng nhiều vai trò**: Sử dụng agent với nhiều quan điểm chuyên môn khác nhau cho các vấn đề phức tạp
3. **Chỉ định trách nhiệm và quyền hạn**: Xác định rõ nhiệm vụ agent cần thực hiện và phạm vi quyết định

### 2.3. Tối ưu hóa cửa sổ ngữ cảnh

Mô hình ngôn ngữ lớn có cửa sổ ngữ cảnh hạn chế, do đó việc thiết kế prompt hiệu quả là rất quan trọng:

-   **Ưu tiên thông tin quan trọng**: Đặt hướng dẫn và thông tin quan trọng nhất ở đầu prompt
-   **Nén thông tin**: Loại bỏ chi tiết không cần thiết và chỉ giữ lại nội dung cốt lõi
-   **Sử dụng định dạng có cấu trúc**: Sử dụng markdown, JSON, v.v. để cấu trúc thông tin
-   **Tận dụng tham chiếu**: Lưu trữ chi tiết trong kho lưu trữ bên ngoài và tham chiếu khi cần

### 2.4. Mẫu prompt và biến hóa

Xây dựng mẫu prompt có thể tái sử dụng giúp duy trì tính nhất quán và nâng cao hiệu quả phát triển:

1. **Prompt mô-đun hóa**: Xây dựng mẫu prompt riêng biệt cho từng chức năng cụ thể
2. **Cơ chế chèn biến**: Triển khai hệ thống mẫu cho phép dễ dàng chèn dữ liệu động
3. **Quản lý phiên bản**: Quản lý phiên bản mẫu prompt để theo dõi thay đổi hiệu suất

Bằng cách liên tục cải thiện và thử nghiệm kỹ thuật prompt, có thể nâng cao hiệu suất, độ tin cậy và trải nghiệm người dùng của A.I Agent.

## 3. Chiến lược sử dụng RAG

RAG (Retrieval Augmented Generation) là một kỹ thuật kết hợp giữa việc truy xuất thông tin từ cơ sở dữ liệu và tạo ra câu trả lời dựa trên thông tin đó.

### 3.1. Agentic RAG

Agentic RAG được thiết kế để tận dụng các đặc điểm của các agent đơn lẻ.

#### 3.1.1. Khái niệm cốt lõi

-   **Tập trung vào nhiệm vụ**: Agentic RAG được thiết kế để tập trung vào một nhiệm vụ cụ thể.
-   **Tổng hợp thông tin**: Kết hợp thông tin từ nhiều nguồn khác nhau để tạo ra câu trả lời chính xác.
-   **Đánh giá kết quả**: Đánh giá kết quả đạt được và tự điều chỉnh để cải thiện hiệu suất.

#### 3.1.2. Ví dụ triển khai

Dưới đây là ví dụ triển khai Agentic RAG:

```python
from langchain.agents import AgentType
from langchain.agents.agent_toolkits import create_prompt_template_agent
from langchain.tools import Tool

# Định nghĩa các công cụ
tools = [
    Tool(name="Search", func=lambda query: {"result": f"Kết quả tìm kiếm cho {query}"}),
    Tool(name="Summarize", func=lambda text: {"summary": f"Tóm tắt: {text}"})
]

# Tạo agent
agent = create_prompt_template_agent(
    AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    tools,
    "Bạn là chuyên gia toán học. Hãy giải quyết câu hỏi sau: {input}"
)

# Ví dụ sử dụng
if __name__ == "__main__":
    result = agent.invoke("Tìm kiếm thông tin về trí tuệ nhân tạo")
    print(result["result"])
```

### 3.2. Adaptive RAG

Adaptive RAG điều chỉnh chiến lược động dựa trên truy vấn và kết quả tìm kiếm. Nếu kết quả tìm kiếm không đủ, nó sẽ viết lại truy vấn hoặc thử các phương pháp tìm kiếm khác.

#### 3.2.1. Khái niệm cốt lõi

-   **Đánh giá kết quả tìm kiếm**: Đánh giá mức độ liên quan và chất lượng của tài liệu tìm được để quyết định bước tiếp theo.
-   **Viết lại truy vấn động**: Sử dụng LLM để viết lại truy vấn chi tiết hơn khi kết quả tìm kiếm không đủ.
-   **Điều chỉnh tham số tìm kiếm**: Điều chỉnh động chiến lược và tham số tìm kiếm để có kết quả tốt hơn.
-   **Nhiều chiến lược tìm kiếm**: Sử dụng nhiều chiến lược tìm kiếm như tìm kiếm ngữ nghĩa, tìm kiếm từ khóa, tìm kiếm lai.

#### 3.2.2. Ví dụ triển khai

Dưới đây là ví dụ triển khai Adaptive RAG sử dụng LangGraph:

```python
from typing import TypedDict, List, Tuple, Literal, Optional, Dict, Any
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END

# Định nghĩa trạng thái
class AdaptiveRAGState(TypedDict):
    question: str
    rewritten_question: Optional[str]
    retrieved_documents: List[str]
    relevance_score: float
    search_strategy: Literal["semantic", "keyword", "hybrid"]
    final_answer: Optional[str]
    attempts: int

# Định nghĩa hàm nút
def retrieve_documents(state: AdaptiveRAGState):
    """Tìm kiếm tài liệu sử dụng chiến lược tìm kiếm hiện tại."""
    query = state.get("rewritten_question", state["question"])

    # Thực tế cần mã kết nối với cơ sở dữ liệu vector
    # Ở đây chỉ cung cấp ví dụ đơn giản
    documents = [
        f"Tài liệu cho {query} sử dụng tìm kiếm {state['search_strategy']}"
    ]

    # Mô phỏng đánh giá chất lượng tìm kiếm
    # Thực tế cần sử dụng LLM hoặc phương pháp đánh giá khác
    if state["attempts"] > 2:
        relevance_score = 0.8  # Giả định kết quả tốt ở lần thử thứ ba
    else:
        relevance_score = 0.4  # Giả định kết quả không tốt ở hai lần đầu

    return {
        "retrieved_documents": documents,
        "relevance_score": relevance_score
    }

def evaluate_results(state: AdaptiveRAGState) -> Literal["rewrite_query", "change_strategy", "generate_answer"]:
    """Đánh giá kết quả tìm kiếm và quyết định bước tiếp theo."""
    # Kiểm tra xem kết quả tìm kiếm có đủ liên quan không
    if state["relevance_score"] >= 0.7:
        return "generate_answer"

    # Kiểm tra số lần thử tối đa
    if state["attempts"] >= 3:
        return "generate_answer"  # Tiếp tục sau khi thử đủ số lần

    # Chọn giữa viết lại truy vấn hoặc thay đổi chiến lược
    if state["attempts"] % 2 == 0:
        return "change_strategy"
    else:
        return "rewrite_query"

def rewrite_query(state: AdaptiveRAGState):
    """Sử dụng LLM để viết lại truy vấn."""
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    response = llm.invoke(
        [HumanMessage(content=f"Vui lòng viết lại câu hỏi sau chi tiết hơn: {state['question']}")]
    )

    return {
        "rewritten_question": response.content,
        "attempts": state["attempts"] + 1
    }

def change_strategy(state: AdaptiveRAGState):
    """Thay đổi chiến lược tìm kiếm."""
    strategies = ["semantic", "keyword", "hybrid"]
    current_index = strategies.index(state["search_strategy"])
    next_index = (current_index + 1) % len(strategies)

    return {
        "search_strategy": strategies[next_index],
        "attempts": state["attempts"] + 1
    }

def generate_answer(state: AdaptiveRAGState):
    """Tạo câu trả lời cuối cùng dựa trên tài liệu tìm được."""
    llm = ChatOpenAI(model="gpt-4")

    context = "\n".join(state["retrieved_documents"])
    query = state.get("rewritten_question", state["question"])

    response = llm.invoke(
        [HumanMessage(content=f"Ngữ cảnh: {context}\n\nCâu hỏi: {query}")]
    )

    return {"final_answer": response.content}

# Xây dựng đồ thị
def build_adaptive_rag_graph():
    workflow = StateGraph(AdaptiveRAGState)

    # Thêm nút
    workflow.add_node("retrieve_documents", retrieve_documents)
    workflow.add_node("rewrite_query", rewrite_query)
    workflow.add_node("change_strategy", change_strategy)
    workflow.add_node("generate_answer", generate_answer)

    # Thêm cạnh có điều kiện
    workflow.add_conditional_edges(
        "retrieve_documents",
        evaluate_results,
        {
            "rewrite_query": "rewrite_query",
            "change_strategy": "change_strategy",
            "generate_answer": "generate_answer"
        }
    )

    # Thêm cạnh còn lại
    workflow.add_edge("rewrite_query", "retrieve_documents")
    workflow.add_edge("change_strategy", "retrieve_documents")
    workflow.add_edge("generate_answer", END)

    # Đặt nút bắt đầu
    workflow.set_entry_point("retrieve_documents")

    return workflow.compile()

# Ví dụ sử dụng
if __name__ == "__main__":
    graph = build_adaptive_rag_graph()
    result = graph.invoke({
        "question": "Vấn đề đạo đức của trí tuệ nhân tạo là gì?",
        "search_strategy": "semantic",
        "attempts": 0
    })
    print(result["final_answer"])
```

### 3.3. Collaborative RAG (CRAG)

Collaborative RAG là cách tiếp cận mà nhiều agent chuyên gia hợp tác để trả lời các câu hỏi phức tạp. Mỗi agent có kiến thức hoặc vai trò chuyên môn khác nhau và cùng nhau tạo ra câu trả lời.

#### 3.3.1. Khái niệm cốt lõi

-   **Nhiều agent chuyên gia**: Các agent từ các lĩnh vực chuyên môn khác nhau hợp tác giải quyết vấn đề.
-   **Hợp tác dựa trên vai trò**: Mỗi agent có vai trò và chuyên môn cụ thể, cung cấp phân tích dựa trên đó.
-   **Đánh giá và cải thiện lẫn nhau**: Các agent đánh giá và phê bình phân tích của nhau để tạo ra câu trả lời tốt hơn.

#### 3.3.2. Ví dụ triển khai

Dưới đây là ví dụ triển khai Collaborative RAG sử dụng LangGraph:

```python
from typing import TypedDict, List, Dict, Optional, Any, Literal
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import json

# Định nghĩa trạng thái
class CRAGState(TypedDict):
    question: str
    context: List[str]
    expert_analyses: Dict[str, str]
    critiques: Dict[str, Dict[str, str]]
    revised_analyses: Dict[str, str]
    final_answer: Optional[str]
    discussion_history: List[BaseMessage]

# Định nghĩa vai trò chuyên gia
EXPERTS = {
    "technical_expert": "Chuyên gia kỹ thuật về cơ sở dữ liệu, lập trình, kiến trúc hệ thống",
    "business_expert": "Chuyên gia về quy trình kinh doanh, xu hướng ngành, chiến lược",
    "legal_expert": "Chuyên gia về quy định dữ liệu, bảo mật thông tin, tuân thủ pháp lý"
}

# Định nghĩa hàm nút
def retrieve_context(state: CRAGState):
    """Tìm kiếm tài liệu liên quan đến câu hỏi."""
    # Thực tế cần logic tìm kiếm cơ sở dữ liệu vector
    # Ở đây chỉ cung cấp ví dụ đơn giản
    context = [
        "Tài liệu về yêu cầu tuân thủ GDPR khi di chuyển cơ sở dữ liệu",
        "Báo cáo phân tích chi phí cơ sở dữ liệu đám mây",
        "Hướng dẫn kỹ thuật di chuyển PostgreSQL lên AWS"
    ]
    return {"context": context}

def generate_expert_analyses(state: CRAGState):
    """Mỗi chuyên gia cung cấp phân tích từ lĩnh vực chuyên môn của mình."""
    llm = ChatOpenAI(model="gpt-4")
    expert_analyses = {}

    for expert_id, expert_desc in EXPERTS.items():
        response = llm.invoke([
            HumanMessage(content=f"""
            Bạn là {expert_desc}.

            Câu hỏi: {state['question']}

            Thông tin liên quan:
            {state['context']}

            Vui lòng trả lời câu hỏi này từ góc độ chuyên môn của bạn.
            """)
        ])
        expert_analyses[expert_id] = response.content

    return {"expert_analyses": expert_analyses}

def critique_analyses(state: CRAGState):
    """Mỗi chuyên gia đánh giá phân tích của các chuyên gia khác."""
    llm = ChatOpenAI(model="gpt-4")
    critiques = {}

    for reviewer_id, reviewer_desc in EXPERTS.items():
        critiques[reviewer_id] = {}

        for author_id, analysis in state["expert_analyses"].items():
            if reviewer_id != author_id:  # Không đánh giá phân tích của chính mình
                response = llm.invoke([
                    HumanMessage(content=f"""
                    Bạn là {reviewer_desc}.

                    Vui lòng xem xét và chỉ ra điểm cần bổ sung trong phân tích sau:

                    Câu hỏi: {state['question']}
                    Phân tích: {analysis}

                    Có quan điểm hoặc cân nhắc quan trọng nào bị thiếu trong phân tích này không?
                    """)
                ])
                critiques[reviewer_id][author_id] = response.content

    return {"critiques": critiques}

def revise_analyses(state: CRAGState):
    """Mỗi chuyên gia sửa đổi phân tích của mình dựa trên phê bình nhận được."""
    llm = ChatOpenAI(model="gpt-4")
    revised_analyses = {}

    for expert_id, expert_desc in EXPERTS.items():
        # Thu thập tất cả phê bình cho chuyên gia này
        all_critiques = []
        for reviewer_id, critiques_by_reviewer in state["critiques"].items():
            if expert_id in critiques_by_reviewer:
                all_critiques.append(critiques_by_reviewer[expert_id])

        critiques_text = "\n\n".join(all_critiques)

        response = llm.invoke([
            HumanMessage(content=f"""
            Bạn là {expert_desc}.

            Phân tích ban đầu của bạn:
            {state['expert_analyses'][expert_id]}

            Phê bình nhận được:
            {critiques_text}

            Vui lòng sửa đổi phân tích của bạn dựa trên các phê bình này.
            """)
        ])
        revised_analyses[expert_id] = response.content

    return {"revised_analyses": revised_analyses}

def collaborative_discussion(state: CRAGState):
    """Các chuyên gia thảo luận cùng nhau để tạo câu trả lời cuối cùng."""
    llm = ChatOpenAI(model="gpt-4")

    # Khởi tạo hoặc lấy lịch sử thảo luận
    history = state.get("discussion_history", [])

    if not history:
        # Bắt đầu thảo luận
        prompt = f"""
        Đây là phân tích đã sửa đổi của các chuyên gia khác nhau về '{state['question']}':

        {json.dumps(state['revised_analyses'], indent=2, ensure_ascii=False)}

        Bây giờ các bạn cần hợp tác để tạo câu trả lời tổng hợp cho câu hỏi này.
        Trước tiên, hãy thảo luận về điểm quan trọng nhất trong phân tích của nhau.
        """
        history.append(HumanMessage(content=prompt))

        # Mỗi chuyên gia phát biểu một lần
        for expert_id, expert_desc in EXPERTS.items():
            response = llm.invoke(history + [
                HumanMessage(content=f"Bạn là {expert_desc}. Vui lòng tham gia thảo luận.")
            ])
            history.append(AIMessage(content=f"[{expert_id}] {response.content}"))

    # Nếu thảo luận đã diễn ra 3 vòng trở lên, tạo câu trả lời cuối cùng
    if len(history) >= 7:  # Prompt ban đầu + 3 chuyên gia mỗi người 2 lần = 7
        final_prompt = "Dựa trên thảo luận cho đến nay, vui lòng viết câu trả lời cuối cùng cho câu hỏi."
        history.append(HumanMessage(content=final_prompt))

        response = llm.invoke(history)
        return {
            "discussion_history": history,
            "final_answer": response.content
        }
    else:
        # Tiếp tục thảo luận
        response = llm.invoke(history + [
            HumanMessage(content="Vui lòng tiếp tục thảo luận. Hãy tích hợp quan điểm của nhau để hướng tới câu trả lời cuối cùng.")
        ])
        history.append(AIMessage(content=response.content))

        return {
            "discussion_history": history
        }

def should_continue_discussion(state: CRAGState) -> Literal["continue", "finish"]:
    """Quyết định tiếp tục thảo luận hay tạo câu trả lời cuối cùng."""
    if state.get("final_answer") is not None:
        return "finish"
    return "continue"

# Xây dựng đồ thị
def build_crag_graph():
    workflow = StateGraph(CRAGState)

    # Thêm nút
    workflow.add_node("retrieve_context", retrieve_context)
    workflow.add_node("generate_expert_analyses", generate_expert_analyses)
    workflow.add_node("critique_analyses", critique_analyses)
    workflow.add_node("revise_analyses", revise_analyses)
    workflow.add_node("collaborative_discussion", collaborative_discussion)

    # Thêm cạnh
    workflow.add_edge("retrieve_context", "generate_expert_analyses")
    workflow.add_edge("generate_expert_analyses", "critique_analyses")
    workflow.add_edge("critique_analyses", "revise_analyses")
    workflow.add_edge("revise_analyses", "collaborative_discussion")

    # Thêm cạnh có điều kiện
    workflow.add_conditional_edges(
        "collaborative_discussion",
        should_continue_discussion,
        {
            "continue": "collaborative_discussion",
            "finish": END
        }
    )

    # Đặt nút bắt đầu
    workflow.set_entry_point("retrieve_context")

    return workflow.compile()

# Ví dụ sử dụng
if __name__ == "__main__":
    graph = build_crag_graph()
    result = graph.invoke({
        "question": "Công ty chúng tôi đang muốn di chuyển cơ sở dữ liệu Oracle từ on-premise lên AWS. Cần cân nhắc những vấn đề gì từ góc độ kỹ thuật, kinh doanh và pháp lý?"
    })
    print(result["final_answer"])
```

### 3.4. Self-RAG

Self-RAG là cách tiếp cận mà LLM tự đánh giá nhu cầu tìm kiếm, đánh giá kết quả tìm kiếm và xác minh chất lượng câu trả lời được tạo ra.

#### 3.4.1. Khái niệm cốt lõi

-   **Đánh giá nhu cầu tìm kiếm**: LLM tự phân tích câu hỏi để xác định có cần tìm kiếm thông tin bên ngoài không.
-   **Đánh giá mức độ liên quan của kết quả tìm kiếm**: Đánh giá mức độ liên quan của tài liệu tìm được với câu hỏi.
-   **Đánh giá độ tin cậy của câu trả lời**: Tự đánh giá độ tin cậy của câu trả lời được tạo ra.
-   **Tự trích dẫn và chỉ định nguồn**: Chỉ rõ nguồn thông tin sử dụng trong câu trả lời.

#### 3.4.2. Ví dụ triển khai

Dưới đây là ví dụ triển khai Self-RAG sử dụng LangGraph:

```python
from typing import TypedDict, List, Dict, Optional, Literal, Any, Tuple
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END

# Định nghĩa trạng thái
class SelfRAGState(TypedDict):
    question: str
    needs_retrieval: bool
    retrieved_documents: List[Dict[str, Any]]
    relevant_documents: List[Dict[str, Any]]
    generated_answer: Optional[str]
    confidence_score: Optional[float]
    final_answer: Optional[str]
    citations: List[Dict[str, Any]]

# Định nghĩa hàm nút
def assess_retrieval_need(state: SelfRAGState):
    """Phân tích câu hỏi để xác định có cần tìm kiếm không."""
    llm = ChatOpenAI(model="gpt-3.5-turbo")

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng phân tích câu hỏi sau để xác định có cần thông tin bên ngoài không:

        "{state['question']}"

        Có cần tìm kiếm thông tin bên ngoài để trả lời câu hỏi này không?
        Chỉ trả lời "Có" hoặc "Không".
        """)
    ])

    needs_retrieval = "Có" in response.content

    return {"needs_retrieval": needs_retrieval}

def decide_next_step(state: SelfRAGState) -> Literal["retrieve", "generate_without_retrieval"]:
    """Quyết định bước tiếp theo dựa trên nhu cầu tìm kiếm."""
    if state["needs_retrieval"]:
        return "retrieve"
    else:
        return "generate_without_retrieval"

def retrieve_documents(state: SelfRAGState):
    """Tìm kiếm tài liệu liên quan đến câu hỏi."""
    # Thực tế cần logic tìm kiếm cơ sở dữ liệu vector
    # Ở đây chỉ cung cấp ví dụ đơn giản
    documents = [
        {"id": "doc1", "content": "LangGraph là framework dựa trên LangChain, cho phép triển khai ứng dụng LLM dưới dạng đồ thị.", "source": "langchain_docs"},
        {"id": "doc2", "content": "RAG (Retrieval-Augmented Generation) là phương pháp cung cấp thông tin bên ngoài cho LLM để tăng độ chính xác và độ tin cậy của câu trả lời.", "source": "research_paper"},
        {"id": "doc3", "content": "Self-RAG là cách tiếp cận mà LLM tự đánh giá nhu cầu tìm kiếm và đánh giá kết quả.", "source": "blog_post"}
    ]

    return {"retrieved_documents": documents}

def assess_document_relevance(state: SelfRAGState):
    """Đánh giá mức độ liên quan của tài liệu tìm được."""
    llm = ChatOpenAI(model="gpt-3.5-turbo")
    relevant_docs = []

    for doc in state["retrieved_documents"]:
        response = llm.invoke([
            HumanMessage(content=f"""
            Vui lòng đánh giá mức độ liên quan của tài liệu sau với câu hỏi:

            Câu hỏi: "{state['question']}"
            Tài liệu: "{doc['content']}"

            Tài liệu này có liên quan đến câu hỏi không?
            Cho điểm từ 0 đến 10.
            Chỉ trả lời bằng số.
            """)
        ])

        try:
            relevance_score = float(response.content.strip())
            if relevance_score >= 7:  # Ngưỡng liên quan
                relevant_docs.append(doc)
        except ValueError:
            # Nếu không chuyển đổi được số, tạm thời bao gồm
            relevant_docs.append(doc)

    return {"relevant_documents": relevant_docs}

def generate_answer_with_retrieval(state: SelfRAGState):
    """Tạo câu trả lời dựa trên tài liệu liên quan."""
    llm = ChatOpenAI(model="gpt-4")

    # Nếu không có tài liệu liên quan, xử lý với ngữ cảnh trống
    if not state["relevant_documents"]:
        context = "Không tìm thấy thông tin liên quan."
    else:
        context = "\n\n".join([doc["content"] for doc in state["relevant_documents"]])

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng trả lời câu hỏi dựa trên thông tin sau:

        Câu hỏi: "{state['question']}"

        Thông tin liên quan:
        {context}

        Khi tạo câu trả lời, vui lòng trích dẫn nguồn thông tin sử dụng dạng [1], [2], v.v.
        """)
    ])

    return {"generated_answer": response.content}

def generate_answer_without_retrieval(state: SelfRAGState):
    """Tạo câu trả lời chỉ sử dụng kiến thức của LLM."""
    llm = ChatOpenAI(model="gpt-4")

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng trả lời câu hỏi sau chỉ sử dụng kiến thức của bạn:

        "{state['question']}"

        Không tìm kiếm thông tin bên ngoài và không đề cập đến nội dung không chắc chắn.
        """)
    ])

    return {"generated_answer": response.content}

def evaluate_confidence(state: SelfRAGState):
    """Đánh giá độ tin cậy của câu trả lời được tạo ra."""
    llm = ChatOpenAI(model="gpt-3.5-turbo")

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng đánh giá độ tin cậy của câu hỏi và câu trả lời sau:

        Câu hỏi: "{state['question']}"
        Câu trả lời: "{state['generated_answer']}"

        Cho điểm từ 0 đến 1.
        Chỉ trả lời bằng số.
        """)
    ])

    try:
        confidence_score = float(response.content.strip())
    except ValueError:
        confidence_score = 0.5  # Giá trị mặc định

    # Trích xuất trích dẫn (triển khai đơn giản)
    citations = []
    if state.get("relevant_documents"):
        for i, doc in enumerate(state["relevant_documents"]):
            if f"[{i+1}]" in state["generated_answer"]:
                citations.append({
                    "citation_id": i+1,
                    "source": doc["source"],
                    "content": doc["content"]
                })

    return {
        "confidence_score": confidence_score,
        "citations": citations
    }

def format_final_answer(state: SelfRAGState):
    """Định dạng câu trả lời cuối cùng bao gồm độ tin cậy và trích dẫn."""
    answer = state["generated_answer"]

    # Thêm tuyên bố miễn trừ trách nhiệm nếu độ tin cậy thấp
    if state["confidence_score"] < 0.7:
        disclaimer = "\n\n(Lưu ý: Câu trả lời này dựa trên thông tin hạn chế và có thể cần xác minh thêm.)"
        answer += disclaimer

    # Thêm thông tin trích dẫn
    if state["citations"]:
        answer += "\n\nNguồn:"
        for citation in state["citations"]:
            answer += f"\n[{citation['citation_id']}] {citation['source']}"

    return {"final_answer": answer}

# Xây dựng đồ thị
def build_self_rag_graph():
    workflow = StateGraph(SelfRAGState)

    # Thêm nút
    workflow.add_node("assess_retrieval_need", assess_retrieval_need)
    workflow.add_node("retrieve_documents", retrieve_documents)
    workflow.add_node("assess_document_relevance", assess_document_relevance)
    workflow.add_node("generate_answer_with_retrieval", generate_answer_with_retrieval)
    workflow.add_node("generate_answer_without_retrieval", generate_answer_without_retrieval)
    workflow.add_node("evaluate_confidence", evaluate_confidence)
    workflow.add_node("format_final_answer", format_final_answer)

    # Thêm cạnh có điều kiện
    workflow.add_conditional_edges(
        "assess_retrieval_need",
        decide_next_step,
        {
            "retrieve": "retrieve_documents",
            "generate_without_retrieval": "generate_answer_without_retrieval"
        }
    )

    # Thêm cạnh thông thường
    workflow.add_edge("retrieve_documents", "assess_document_relevance")
    workflow.add_edge("assess_document_relevance", "generate_answer_with_retrieval")
    workflow.add_edge("generate_answer_with_retrieval", "evaluate_confidence")
    workflow.add_edge("generate_answer_without_retrieval", "evaluate_confidence")
    workflow.add_edge("evaluate_confidence", "format_final_answer")
    workflow.add_edge("format_final_answer", END)

    # Đặt nút bắt đầu
    workflow.set_entry_point("assess_retrieval_need")

    return workflow.compile()

# Ví dụ sử dụng
if __name__ == "__main__":
    graph = build_self_rag_graph()
    result = graph.invoke({
        "question": "Vui lòng giải thích cách triển khai Self-RAG sử dụng LangGraph."
    })
    print(result["final_answer"])
```

## 4. Mẫu Plan & Execute

Plan & Execute là mẫu hữu ích khi A.I Agent dựa trên LLM thực hiện các nhiệm vụ phức tạp, trong đó trước tiên lập kế hoạch tổng thể sau đó thực hiện từng bước tuần tự. Có thể triển khai hiệu quả mẫu này bằng cách sử dụng LangGraph.

### 4.1. Khái niệm cốt lõi

-   **Giai đoạn lập kế hoạch (Planning)**: Lập kế hoạch trước các bước chi tiết để đạt được mục tiêu tổng thể.
-   **Giai đoạn thực hiện (Execution)**: Thực hiện tuần tự từng bước đã lập kế hoạch.
-   **Quản lý trạng thái**: Theo dõi tiến trình và kết quả trung gian.

### 4.2. Ưu điểm

-   **Phân tách công việc phức tạp thành các bước quản lý được**: Chia nhỏ công việc lớn thành các bước nhỏ hơn để xử lý.
-   **Tiến triển nhất quán hướng tới mục tiêu dài hạn**: Duy trì định hướng nhất quán dựa trên kế hoạch tổng thể.
-   **Tận dụng kết quả của mỗi bước cho bước tiếp theo**: Sử dụng kết quả của từng bước làm đầu vào cho bước tiếp theo.
-   **Có thể sửa đổi kế hoạch khi thất bại**: Có thể sửa đổi kế hoạch và thử lại khi gặp vấn đề.

### 4.3. Ví dụ triển khai

Dưới đây là ví dụ triển khai mẫu Plan & Execute sử dụng LangGraph:

```python
from typing import TypedDict, List, Dict, Optional, Any
from langchain_core.messages import HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
import json

# Định nghĩa trạng thái
class PlanExecuteState(TypedDict):
    goal: str
    plan: List[Dict[str, Any]]
    current_step: int
    completed_steps: List[Dict[str, Any]]
    final_result: Optional[str]
    error: Optional[str]

# Định nghĩa hàm nút
def create_plan(state: PlanExecuteState):
    """Tạo kế hoạch để đạt được mục tiêu."""
    llm = ChatOpenAI(model="gpt-4")

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng viết kế hoạch từng bước để đạt được mục tiêu sau:

        Mục tiêu: {state['goal']}

        Mỗi bước phải được viết dưới dạng JSON như sau:
        {{
            "step": số bước,
            "description": "mô tả bước",
            "expected_output": "đầu ra dự kiến",
            "dependencies": [số bước trước đó]
        }}

        Vui lòng trả lời dưới dạng mảng JSON.
        """)
    ])

    try:
        plan = json.loads(response.content)
    except json.JSONDecodeError:
        # Nếu không phân tích được JSON, tạo kế hoạch mặc định
        plan = [
            {
                "step": 1,
                "description": "Phân tích mục tiêu",
                "expected_output": "Danh sách yêu cầu chính của mục tiêu",
                "dependencies": []
            },
            {
                "step": 2,
                "description": "Xác định tài nguyên cần thiết",
                "expected_output": "Danh sách tài nguyên cần thiết",
                "dependencies": [1]
            },
            {
                "step": 3,
                "description": "Lập kế hoạch thực hiện",
                "expected_output": "Kế hoạch thực hiện chi tiết",
                "dependencies": [1, 2]
            }
        ]

    return {"plan": plan, "current_step": 0}

def check_step_dependencies(state: PlanExecuteState) -> Literal["ready", "wait"]:
    """Kiểm tra xem các phụ thuộc của bước hiện tại đã được đáp ứng chưa."""
    current_step = state["plan"][state["current_step"]]
    dependencies = current_step.get("dependencies", [])

    # Kiểm tra phụ thuộc
    for dep in dependencies:
        if not any(step["step"] == dep for step in state["completed_steps"]):
            return "wait"

    return "ready"

def execute_step(state: PlanExecuteState):
    """Thực hiện bước hiện tại."""
    llm = ChatOpenAI(model="gpt-4")
    current_step = state["plan"][state["current_step"]]

    # Thu thập kết quả của các bước trước
    previous_results = "\n".join([
        f"Kết quả bước {step['step']}: {step['result']}"
        for step in state["completed_steps"]
    ])

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng thực hiện bước sau:

        Mục tiêu: {state['goal']}

        Bước hiện tại:
        - Số bước: {current_step['step']}
        - Mô tả: {current_step['description']}
        - Đầu ra dự kiến: {current_step['expected_output']}

        Kết quả các bước trước:
        {previous_results}

        Vui lòng thực hiện bước này và tạo kết quả.
        """)
    ])

    # Lưu kết quả bước
    completed_step = {
        "step": current_step["step"],
        "description": current_step["description"],
        "result": response.content
    }

    return {
        "completed_steps": state["completed_steps"] + [completed_step],
        "current_step": state["current_step"] + 1
    }

def check_completion(state: PlanExecuteState) -> Literal["continue", "finish"]:
    """Kiểm tra xem tất cả các bước đã hoàn thành chưa."""
    if state["current_step"] >= len(state["plan"]):
        return "finish"
    return "continue"

def generate_final_result(state: PlanExecuteState):
    """Tạo kết quả cuối cùng."""
    llm = ChatOpenAI(model="gpt-4")

    # Thu thập kết quả của tất cả các bước
    all_results = "\n".join([
        f"Bước {step['step']}: {step['description']}\nKết quả: {step['result']}\n"
        for step in state["completed_steps"]
    ])

    response = llm.invoke([
        HumanMessage(content=f"""
        Vui lòng tạo kết quả cuối cùng dựa trên mục tiêu và kết quả từng bước sau:

        Mục tiêu: {state['goal']}

        Kết quả từng bước:
        {all_results}

        Vui lòng tổng hợp kết quả của tất cả các bước để tạo kết quả cuối cùng.
        """)
    ])

    return {"final_result": response.content}

# Xây dựng đồ thị
def build_plan_execute_graph():
    workflow = StateGraph(PlanExecuteState)

    # Thêm nút
    workflow.add_node("create_plan", create_plan)
    workflow.add_node("check_dependencies", check_step_dependencies)
    workflow.add_node("execute_step", execute_step)
    workflow.add_node("generate_final_result", generate_final_result)

    # Thêm cạnh có điều kiện
    workflow.add_conditional_edges(
        "check_dependencies",
        check_step_dependencies,
        {
            "ready": "execute_step",
            "wait": "check_dependencies"
        }
    )

    workflow.add_conditional_edges(
        "execute_step",
        check_completion,
        {
            "continue": "check_dependencies",
            "finish": "generate_final_result"
        }
    )

    # Thêm cạnh thông thường
    workflow.add_edge("create_plan", "check_dependencies")
    workflow.add_edge("generate_final_result", END)

    # Đặt nút bắt đầu
    workflow.set_entry_point("create_plan")

    return workflow.compile()

# Ví dụ sử dụng
if __name__ == "__main__":
    graph = build_plan_execute_graph()
    result = graph.invoke({
        "goal": "Lập kế hoạch thiết kế và triển khai hệ thống quản lý tài liệu dựa trên web"
    })
    print(result["final_result"])
```

### 4.4. Mẹo sử dụng

Dưới đây là một số mẹo chính để sử dụng hiệu quả mẫu Plan & Execute:

#### Mẹo prompt cho giai đoạn lập kế hoạch

1. **Chỉ định mục tiêu và công cụ**

    - Trình bày mục tiêu chính xác và cung cấp danh sách công cụ có sẵn.
    - Điều này giúp LLM tạo kế hoạch thực tế có tính đến việc sử dụng công cụ.

2. **Giới hạn phạm vi kế hoạch**
    - Giới hạn số lượng bước tối đa để tránh tạo kế hoạch quá chi tiết.
    - Điều chỉnh phạm vi của mỗi bước để tạo kế hoạch khả thi.

#### Mẹo prompt cho giai đoạn thực hiện

1. **Tránh thực hiện trùng lặp**

    - Tránh gọi công cụ lặp lại với cùng điều kiện và tham số.
    - Sử dụng bộ nhớ cache hoặc quản lý trạng thái để giảm thiểu thực hiện không cần thiết.

2. **Quản lý ngữ cảnh thực hiện**

    - Cung cấp rõ ràng thông tin ngữ cảnh cần thiết cho mỗi bước thực hiện.
    - Tận dụng hiệu quả kết quả của các bước trước để duy trì tính liên tục.

3. **Xử lý lỗi và khôi phục**
    - Xem xét trước các tình huống lỗi có thể xảy ra trong mỗi bước thực hiện.
    - Triển khai chiến lược khôi phục phù hợp để tăng tính ổn định của toàn bộ quy trình.
