# LangChain Overview

## 1. Large Language Model (LLM)

### 1.1. Language Model

**Language Model** l√† m·ªôt model x√°c su·∫•t m√† c√≥ th·ªÉ sinh ra t·ª´ ng·ªØ d·ª±a tr√™n l∆∞·ª£ng d·ªØ li·ªáu m√† n√≥ ƒë∆∞·ª£c train. Nh∆∞ng th·∫≠t ra, n√≥ kh√¥ng hi·ªÉu ng√¥n ng·ªØ ƒë√≥.

Gi·∫£ s·ª≠, ta c√≥ nu√¥i m·ªôt con v·∫πt. Con v·∫πt n√†y s·∫Ω nghe ta n√≥i c√¢u ‚ÄúT√¥i ƒë√≥i qu√°, t√¥i mu·ªën ƒÉn **b√°nh m√¨**‚Äù r·∫•t nhi·ªÅu l·∫ßn. Cho ƒë·∫øn m·ªôt ng√†y, ta ch·ªâ c·∫ßn n√≥i ‚ÄúT√¥i ƒë√≥i qu√°, t√¥i mu·ªën ƒÉn‚Ä¶‚Äù, con v·∫πt s·∫Ω t·ª± ƒë·ªông tr·∫£ l·ªùi l√† ‚Äúb√°nh m√¨‚Äù.

![Untitled](LangChainOverview/Untitled.png)

Con v·∫πt ch√≠nh l√† **Language Model**. N√≥ l√† m·ªôt th·ª© ƒë∆∞·ª£c train r·∫•t nhi·ªÅu ƒë·ªÉ r·ªìi khi ta ƒë∆∞a input l√† prompt (c√¢u n√≥i ch∆∞a ho√†n thi·ªán), LM s·∫Ω cho ta output ph√π h·ª£p v·ªõi prompt ƒë√≥. D√π con v·∫πt kh√¥ng hi·ªÉu ta ƒëang n√≥i g√¨, nh∆∞ng v√¨ con v·∫πt nghe ta n√≥i h√†ng ng√†y, n√≥ s·∫Ω c√≥ th·ªÉ ho√†n thi·ªán c√¢u n√≥i c·ªßa ta b·∫±ng t·ª´ c√≥ **x√°c su·∫•t cao nh·∫•t**.

![LM s·∫Ω ƒë∆∞a ra c√¢u tr·∫£ l·ªùi c√≥ x√°c su·∫•t xu·∫•t hi·ªán l·ªõn nh·∫•t trong dataset m√† n√≥ ƒë∆∞·ª£c train](LangChainOverview/Untitled%201.png)

LM s·∫Ω ƒë∆∞a ra c√¢u tr·∫£ l·ªùi c√≥ x√°c su·∫•t xu·∫•t hi·ªán l·ªõn nh·∫•t trong dataset m√† n√≥ ƒë∆∞·ª£c train

### 1.2. Large Language Model (LLM)

**Large Language Model (LLM)** l√† m·ªôt lo·∫°i thu·∫≠t to√°n m√† s·ª≠ d·ª•ng deep learning v√† ƒë∆∞·ª£c train b·ªüi nh·ªØng data set r·∫•t l·ªõn ƒë·ªÉ hi·ªÉu, t√≥m t·∫Øt, sinh, d·ª± ƒëo√°n c√°c th√¥ng tin.

![LLM l√† m·ªôt ph·∫ßn c·ªßa DL](LangChainOverview/Untitled%202.png)

LLM l√† m·ªôt ph·∫ßn c·ªßa DL

Con v·∫πt h√†ng ng√†y n√≥ l·ªõn d·∫ßn, n√≥ bay ƒëi kh·∫Øp n∆°i v√† nghe r·∫•t nhi·ªÅu ng∆∞·ªùi n√≥i. Sau m·ªôt th·ªùi gian, nh·ªØng th√¥ng tin s·∫Ω li√™n k·∫øt v·ªõi nhau th√†nh m·ªôt m·∫°ng n∆°-ron trong n√£o n√≥ n√™n n√≥ c√≥ th·ªÉ tr·∫£ l·ªùi ƒë∆∞·ª£c nh·ªØng c√¢u h·ªèi logic ph·ª©c t·∫°p h∆°n r·∫•t nhi·ªÅu.

N√≥ kh√¥ng c√≤n ch·ªâ l√† ho√†n thi·ªán c√¢u n√≥i n·ªØa m√† n√≥ c√≥ th·ªÉ tr·∫£ l·ªùi nh·ªØng c√¢u h·ªèi ph·ª©c t·∫°p. L√∫c n√†y con v·∫πt gi·ªëng nh∆∞ m·ªôt **Large Language Model** - m·ªôt th·ª±c th·ªÉ ƒë√£ ƒë∆∞·ª£c train b·ªüi m·ªôt l∆∞·ª£ng d·ªØ li·ªáu r·∫•t l·ªõn. L√∫c n√†y, con v·∫πt th·ª±c s·ª± ƒë√£ hi·ªÉu nh·ªØng g√¨ m√† ta n√≥i.

![LLM c√≥ th·ªÉ hi·ªÉu v√† tr·∫£ l·ªùi ƒë∆∞·ª£c nh·ªØng c√¢u h·ªèi ph·ª©c t·∫°p h∆°n](LangChainOverview/Untitled%203.png)

LLM c√≥ th·ªÉ hi·ªÉu v√† tr·∫£ l·ªùi ƒë∆∞·ª£c nh·ªØng c√¢u h·ªèi ph·ª©c t·∫°p h∆°n

C√°c model ƒë∆∞·ª£c train b·ªüi c√°c dataset kh√°c nhau s·∫Ω ƒë∆∞a ra nh·ªØng output kh√°c nhau.

![Untitled](LangChainOverview/Untitled%204.png)

T·∫°i sao l·∫°i g·ªçi l√† ‚Äú**Large**‚Äù Languague Model?

1. **C√≥ s·ªë l∆∞·ª£ng c√°c parameter c·ª±c l·ªõn** (m·∫°ng n∆°-ron c√≥ nhi·ªÅu layer, m·ªëi layer c√≥ nhi·ªÅu unit; c√°c parameters s·∫Ω ƒë∆∞·ª£c sinh ra t·ª´ ƒë∆∞·ªùng k·∫øt n·ªëi c√°c unit v·ªõi nhau)
   - GPT-3.5 c√≥ s·ªë l∆∞·ª£ng parameter l√† 1.3 t·ªâ (v·ªÅ sau tƒÉng l√™n 175 t·ªâ)
   - GPT-4 c√≥ s·ªë l∆∞·ª£ng parameter l√† 1.76 ngh√¨n t·ªâ
2. **ƒê∆∞·ª£c train tr√™n m·ªôt l∆∞·ª£ng data set c·ª±c l·ªõn**
   - GPT-3.5 ƒë∆∞·ª£c train b·ªüi 45TB text data (C·∫ßn kho·∫£ng 75 ngh√¨n nƒÉm ƒë·ªÉ con ng∆∞·ªùi c√≥ th·ªÉ ƒë·ªçc h·∫øt s·ªë th√¥ng tin ƒë√≥)

ƒê·ªÉ train ChatGPT, ta c·∫ßn kho·∫£ng 10.000 Nvidia GPUs

LLM c√≥ th·ªÉ l√†m g√¨?

- D·ªãch ng√¥n ng·ªØ
- T·ªïng h·ª£p, t√≥m t·∫Øt vƒÉn b·∫£n
- Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
- Ph√¢n t√≠ch c·∫£m x√∫c c·ªßa m·ªôt ƒëo·∫°n vƒÉn
- Sinh ra c√¢u tr·∫£ l·ªùi ph√π h·ª£p v·ªõi input, ng·ªØ c·∫£nh c·ªßa ng∆∞·ªùi d√πng

## 2. Transformer

### 2.1. T·∫°i sao l·∫°i l√† Transformer?

Transformer l√† ki·∫øn tr√∫c c·ªët l√µi c·ªßa c√°c LLM. C·ª• th·ªÉ nh∆∞ n√†o th√¨ s·∫Ω kh√¥ng gi·∫£i th√≠ch ·ªü ƒë√¢y v√¨ r·∫•t ph·ª©c t·∫°p üò¢

Ta c√≥ th·ªÉ d√πng c√°c ki·∫øn tr√∫c kh√°c nh∆∞ **Recurrent Neural Network (RNN)** ƒë·ªÉ x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n nh∆∞ng t·∫°i sao ph·∫£i s·ª≠ d·ª•ng **Transformer**?

- V·ªõi ki·∫øn tr√∫c c·ªßa m·∫°ng **RNN**, c√°c t·ª´ s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o m·∫°ng m·ªôt c√°ch **l·∫ßn l∆∞·ª£t**. V√¨ v·∫≠y, ta kh√¥ng th·ªÉ train d·ªØ li·ªáu m·ªôt c√°ch song song. H·ªá qu·∫£ l√† vi·ªác train s·∫Ω m·∫•t r·∫•t nhi·ªÅu th·ªùi gian, kh√¥ng t·∫≠n d·ª•ng ƒë∆∞·ª£c vi·ªác ch·∫°y song song c·ªßa GPU v√† ƒë·ªëi v·ªõi nh·ªØng c√¢u vƒÉn d√†i, nh·ªØng t·ª´ ·ªü ƒë·∫ßu c√¢u s·∫Ω m·∫•t li√™n h·ªá v·ªõi nh·ªØng t·ª´ ·ªü cu·ªëi.
  ![Untitled](LangChainOverview/Untitled%205.png)
- V·ªõi ki·∫øn tr√∫c **Transformer**, ta c√≥ th·ªÉ ƒë∆∞a **ƒë·ªìng th·ªùi** c·∫£ c√¢u vƒÉn v√†o m·∫°ng ƒë·ªÉ x·ª≠ l√Ω v√† l·∫•y ra output l√† c·∫£ m·ªôt c√¢u thay v√¨ ph·∫£i ƒë∆∞a t·ª´ng t·ª´ v√†o nh∆∞ RNN. Tuy nhi√™n, khi s·ª≠ d·ª•ng Transformer, ta c·∫ßn l∆∞u √Ω 2 ƒëi·ªÅu sau:
  - **Positional Encoding**: ƒê√°nh d·∫•u xem t·ª´ n√†o v√†o tr∆∞·ªõc, t·ª´ n√†o v√†o sau ƒë·ªÉ b·∫£o to√†n √Ω nghƒ©a c·ªßa c√¢u
  - **Attention v√† Self-Attention**: Gi√∫p c√°c t·ª´ ng·ªØ trong c√¢u gi·ªØ ƒë∆∞·ª£c li√™n h·ªá v·ªõi nhau v·ªÅ m·∫∑t logic (VD: Th∆°m v√† d·ª©a,‚Ä¶)
  ![Untitled](LangChainOverview/Untitled%206.png)

### 2.2. Finetuning

M·ªôt LLM c√≥ th·ªÉ x·ª≠ l√Ω nhi·ªÅu lo·∫°i c√°c c√¥ng vi·ªác v√† lƒ©nh v·ª±c kh√°c nhau. Tuy nhi√™n, **finetuning** s·∫Ω gi√∫p model hi·ªáu qu·∫£ h∆°n.

**Finetuning** mu·ªën n√≥i ƒë·∫øn vi·ªác ta l·∫•y m·ªôt pre-trained model v√† train n√≥ d·ª±a tr√™n m·ªôt t·∫≠p dataset c·ª• th·ªÉ h∆°n v·ªÅ m·ªôt lƒ©nh v·ª±c n√†o ƒë√≥ (dataset n√†y th∆∞·ªùng nh·ªè h∆°n nhi·ªÅu so v·ªõi dataset c·ªßa pre-trained model nh∆∞ng s·∫Ω chuy√™n s√¢u v·ªÅ m·ªôt lƒ©nh v·ª±c h∆°n)

![Untitled](LangChainOverview/Untitled%207.png)

## 3. LangChain

### 3.1. Gi·ªõi thi·ªáu

**LangChain** l√† m·ªôt framework gi√∫p ta ph√°t tri·ªÉn c√°c ·ª©ng d·ª•ng s·ª≠ d·ª•ng LLM.

N√≥ cho ph√©p ·ª©ng d·ª•ng:

- **Suy lu·∫≠n logic**: T·∫≠n d·ª•ng LLM ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi logic
- **Nh·∫≠n bi·∫øt ng·ªØ c·∫£nh**: Gi√∫p LLM bi·∫øt ƒë∆∞·ª£c ng·ªØ c·∫£nh c·ªßa c√¢u h·ªèi ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ph√π h·ª£p
- **K·∫øt n·ªëi LLM v·ªõi ki·∫øn th·ª©c b√™n ngo√†i**: Cung c·∫•p th√™m cho LLM embedding information (text, pdf, image,‚Ä¶) ƒë·ªÉ c√≥ ƒë∆∞·ª£c c√¢u tr·∫£ l·ªùi t·ªët nh·∫•t

Framework n√†y g·ªìm nhi·ªÅu ph·∫ßn ph·∫ßn:

- **LangChain Libraries**: H·ªó tr·ª£ cho Python v√† JavaScript. N√≥ cung c·∫•p:
  - C√°c interface v√† t√≠ch h·ª£p cho h√†ng lo·∫°t c√°c components (text splitter, prompt template,‚Ä¶)
  - M·ªôt run time ƒë∆°n gi·∫£n ƒë·ªÉ k·∫øt h·ª£p nh·ªØng component n√†y th√†nh chains v√† agents
  - Nh·ªØng c√†i ƒë·∫∑t c√≥ s·∫µn c·ªßa chains v√† agents
- **[LangChain Templates](https://python.langchain.com/docs/templates)**: M·ªôt t·∫≠p c√°c ki·∫øn tr√∫c tham chi·∫øu m√† d·ªÖ d√†ng tri·ªÉn khai cho nhi·ªÅu lo·∫°i nhi·ªám v·ª• kh√°c nhau. (Python only)
- **[LangServe](https://python.langchain.com/docs/langserve)**: M·ªôt th∆∞ vi·ªán ƒë·ªÉ tri·ªÉn khai c√°c chain c·ªßa LangChain d∆∞·ªõi d·∫°ng m·ªôt REST API. (Python only)
- **[LangSmith](https://smith.langchain.com/)**: M·ªôt n·ªÅn t√†ng l·∫≠p tr√¨nh cho ph√©p ta debug, test, ƒë√°nh gi√° v√† gi√°m s√°t chains m√† ƒë∆∞·ª£c x√¢y d·ª±ng tr√™n b·∫•t k·ª≥ LLM framework n√†o v√† t√≠ch h·ª£p li·ªÅn m·∫°ch v·ªõi LangChain.

![Untitled](LangChainOverview/Untitled%208.png)

### 3.2. Lu·ªìng ho·∫°t ƒë·ªông c·ªßa LangChain

![Untitled](LangChainOverview/Untitled%209.png)

- Chu·∫©n b·ªã d·ªØ li·ªáu: Chu·∫©n b·ªã nh·ªØng file pdf, website,‚Ä¶ ƒë·ªÉ ta chia nh·ªè, tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng v√† ƒë∆∞a v√†o Vector DB
  - Vector DB c√≥ nhi·ªÅu lo·∫°i. C√≥ th·ªÉ d√πng Faiss, ChromaDB,‚Ä¶ Ta c·∫ßn index cho DB n√†y ƒë·ªÉ d·ªÖ d√†ng t√¨m ki·∫øm
- Khi ng∆∞·ªùi d√πng nh·∫≠p v√†o m·ªôt Query, ta s·ª≠ ƒë∆∞a query ƒë√≥ v√†o Prompt Template (Chain) v√† g·ª≠i n√≥ qua m·ªôt Embedding Model ƒë·ªÉ tr√≠ch xu·∫•t vector ƒë·∫∑c tr∆∞ng, ƒë∆∞a n√≥ v√†o Query DB.
- Query DB s·∫Ω so s√°nh v·ªõi Vector DB ƒë·ªÉ l·∫•y ra nh·ªØng Related Document (th√¥ng tin li√™n quan) r·ªìi g·ª≠i Related Document v√† Prompt t·ªõi LLM.
- LLM s·∫Ω d·ª±a v√†o ƒë√≥ ƒë·ªÉ s√¨nh ra Response

### 3.3. C√°c component c∆° b·∫£n trong LangChain

M·ªôt s·ªë component c∆° b·∫£n c·ªßa LangChain g·ªìm:

- **Model**: L√† LLM ƒë·ªÉ sinh ra c√¢u tr·∫£ l·ªùi cho ng∆∞·ªùi d√πng
- **Embedding model - Retrieval model**: LLM ƒë·ªÉ
  - tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (vector) c·ªßa b·ªëi c·∫£nh
  - tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (vector) t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
- **Chain**: L√† m·ªôt chu·ªói c√°c m·∫Øt x√≠ch, m·ªói m·∫Øt x√≠ch s·∫Ω l√†m m·ªôt c√¥ng vi·ªác c·ª• th·ªÉ, r·ªìi chuy·ªÉn output c·ªßa n√≥ th√†nh input cho m·∫Øt x√≠ch sau
- **Prompt template**: Gi√∫p ta t·∫°o ra prompt m·ªôt c√°ch d·ªÖ d√†ng, c√≥ th·ªÉ truy·ªÅn c√°c tham s·ªë v√†o
- **Output parser**: Gi√∫p ta ƒë·ªãnh nghƒ©a ra format c·ªßa output
- **Document loader**: Gi√∫p ta ƒë·ªçc th√¥ng tin t·ª´ file, website,‚Ä¶
- **Vector - document**: L√† nh·ªØng ƒë·∫∑c tr∆∞ng c·ªßa m·ªôt th√¥ng tin n√†o ƒë√≥
- **Vectorstore - Vector DB**: T·∫≠p nhi·ªÅu vector
- **Text splitter**: Gi√∫p ta chia document th√†nh nhi·ªÅu ph·∫ßn nh·ªè h∆°n (v√¨ model c√≥ gi·ªõi h·∫°n k√≠ch th∆∞·ªõc c·ªßa token truy·ªÅn v√†o)
- **Retriever**: Xem x√©t ƒë·∫∑c tr∆∞ng c·ªßa c√¢u h·ªèi r·ªìi l·ª±a ch·ªçn nh·ªØng ƒë·∫∑c tr∆∞ng li√™n quan c·ªßa b·ªëi c·∫£nh ƒë·ªÉ truy·ªÅn cho Model.
- **Agent**: L√† nh·ªØng c√¥ng c·ª• gi√∫p ta c√≥ th·ªÉ quy·∫øt ƒë·ªãnh xem c√≥ c·∫ßn search th√™m th√¥ng tin tr√™n web hay kh√¥ng.

### 3.4. Th·ª±c h√†nh v·ªõi LLM Chain

C√†i ƒë·∫∑t:

```bash
npm install @langchain/openai
```

Bi·∫øn m√¥i tr∆∞·ªùng:

```bash
OPENAI_API_KEY="..."
```

ƒê√¢y l√† v√≠ d·ª• s·ª≠ d·ª•ng LangChain v·ªõi input l√† m·ªôt message ƒë∆°n gi·∫£n.

```jsx
import { ChatOpenAI } from "@langchain/openai";

const chatModel = new ChatOpenAI({
  model: "gpt-3.5-turbo",
  apiKey: process.env.OPENAI_API_KEY,
});

const data = await chatModel.invoke("what is LangSmith?");
console.log(data);
```

```json
AIMessage {
  content: 'LangSmith refers to the combination of two surnames, Lang and Smith. It is most commonly used as a fictional or hypothetical name for a person or a company. This term may also refer to specific individuals or entities named LangSmith in certain contexts.',
  additional_kwargs: { function_call: undefined, tool_calls: undefined }
}
```

**Nh·∫≠n x√©t**: K·∫øt qu·∫£ c·ªßa v√≠ d·ª• n√†y kh√¥ng li√™n quan ƒë·ªÉ ƒëi·ªÅu m√† ta mu·ªën h·ªèi. Nguy√™n nh√¢n l√† n√≥ kh√¥ng hi·ªÉu ƒë∆∞·ª£c b·ªëi c·∫£nh k·ªπ thu·∫≠t c·ªßa ta

S·ª≠ d·ª•ng LangChain v·ªõi **prompt template**. **Prompt template** s·∫Ω chuy·ªÉn ƒë·ªïi input c·ªßa user th√†nh m·ªôt input kh√°c t·ªët h∆°n d√†nh cho LLM.

V·ªõi prompt template, ta c√≥ th·ªÉ cung c·∫•p **b·ªëi c·∫£nh** cho chatModel, t·ª´ ƒë√≥ gi√∫p ta c√≥ ƒë∆∞·ª£c response ph√π h·ª£p h∆°n.

```jsx
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const chatModel = new ChatOpenAI({
  model: "gpt-3.5-turbo",
  apiKey: process.env.OPENAI_API_KEY,
});

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a world class technical documentation writer."],
  ["user", "{input}"],
]);

const chain = prompt.pipe(chatModel);

const data = await chain.invoke({
  input: "what is LangSmith?",
});
console.log(data);
```

```json
AIMessage {
  content: 'LangSmith is a powerful programming language created for high-performance software development. It is designed to be efficient, intuitive, and capable of handling complex computations and data manipulations. With its extensive set of features and libraries, LangSmith provides developers with the tools necessary to build robust and scalable applications.\n' +
    '\n' +
    'Some key features of LangSmith include:\n' +
    '\n' +
    '1. Strong typing: LangSmith enforces type safety, preventing common programming errors and ensuring code reliability.\n' +
    '\n' +
    '2. Advanced memory management: The language provides built-in memory management mechanisms, such as automatic garbage collection, to optimize memory usage and reduce the risk of memory leaks.\n' +
    ... +
    'Overall, LangSmith aims to provide a robust and efficient development environment for creating software applications across various domains, from scientific simulations to web development and beyond.',
  additional_kwargs: { function_call: undefined, tool_calls: undefined }
}
```

**Nh·∫≠n x√©t**: K·∫øt qu·∫£ c·ªßa v√≠ d·ª• n√†y d√π v·∫´n kh√¥ng ch√≠nh x√°c nh∆∞ng n√≥ ƒëang mang t√≠nh k·ªπ thu·∫≠t h∆°n so v·ªõi response tr∆∞·ªõc.

Output c·ªßa ChatModel ƒëang l√† m·ªôt message object. Nh∆∞ng s·∫Ω d·ªÖ d√†ng h∆°n n·∫øu nh∆∞ ta l√†m vi·ªác v·ªõi string. Ta s·∫Ω th√™m m·ªôt **output parser** ƒë∆°n gi·∫£n ƒë·ªÉ convert message th√†nh m·ªôt string.

```jsx
import { ChatOpenAI } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { StringOutputParser } from "@langchain/core/output_parsers";

const outputParser = new StringOutputParser();

const chatModel = new ChatOpenAI({
  model: "gpt-3.5-turbo",
  apiKey: process.env.OPENAI_API_KEY,
});

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "You are a world class technical documentation writer."],
  ["user", "{input}"],
]);

const llmChain = prompt.pipe(chatModel).pipe(outputParser);

const data = await llmChain.invoke({
  input: "what is LangSmith?",
});

console.log(data);
```

```json
LangSmith is a sophisticated online language translation tool. It leverages artificial intelligence and machine learning algorithms to provide accurate and efficient translation services across multiple languages. Whether it's translating documents, websites, or text snippets, LangSmith offers a seamless, user-friendly experience while maintaining the integrity and nuances of the original content. Its advanced features include context-aware translations, language customization options, and quality assurance checks, making it an invaluable tool for businesses, individuals, and language professionals alike.
```

### 3.5. Th·ª±c h√†nh v·ªõi retrieval chain

ƒê·ªÉ c√¢u tr·∫£ l·ªùi c·ªßa c√¢u h·ªèi "what is LangSmith?‚Äù ƒë∆∞·ª£c ch√≠nh x√°c, ta c·∫ßn cung c·∫•p th√™m b·ªëi c·∫£nh cho LLM. Ta c√≥ th·ªÉ s·ª≠ d·ª•ng **retrieval** ƒë·ªÉ l√†m vi·ªác n√†y. Retrieval cho ph√©p ta truy·ªÅn nhi·ªÅu d·ªØ li·ªáu v√†o LLM m·ªôt c√°ch tr·ª±c ti·∫øp. Sau ƒë√≥, ta c√≥ th·ªÉ s·ª≠ d·ª•ng **retriever** ƒë·ªÉ ch·ªâ fetch nh·ªØng ph·∫ßn d·ªØ li·ªáu ph√π h·ª£p nh·∫•t.

Ta s·∫Ω c·ªë g·∫Øng l·∫•y d·ªØ d·ªØ li·ªáu ph√π h·ª£p b·∫±ng Retriever v√† truy·ªÅn n√≥ v√†o prompt. Retriever c√≥ th·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ b·ªüi SQL table, internet,‚Ä¶ nh∆∞ng trong tr∆∞·ªùng h·ª£p n√†y, ta s·∫Ω populate m·ªôt vector store v√† d√πng n√≥ nh∆∞ m·ªôt retriever. For more information on vectorstores, see¬†[this documentation](https://js.langchain.com/docs/modules/data_connection/vectorstores).

ƒê·∫ßu ti√™n, ta c·∫ßn **load d·ªØ li·ªáu m√† ta mu·ªën index**. Ta s·∫Ω s·ª≠ d·ª•ng m·ªôt [**document loader**](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/web_cheerio) d·ª±a tr√™n **Cheerio** (th∆∞ vi·ªán ƒë·ªÉ c√†o d·ªØ li·ªáu) ƒë·ªÉ l·∫•y d·ªØ li·ªáu t·ª´ webpage.

C√†i ƒë·∫∑t th∆∞ vi·ªán:

```bash
npm install cheerio
```

Code nh∆∞ sau:

```jsx
import { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";

const loader = new CheerioWebBaseLoader(
  "https://docs.smith.langchain.com/user_guide"
);

const docs = await loader.load();

console.log(docs.length);
console.log(docs[0].pageContent.length);
```

```jsx
1;
36542;
```

L∆∞u √Ω r·∫±ng k√≠ch th∆∞·ªõc c·ªßa loaded document (d·ªØ li·ªáu ƒë∆∞·ª£c c√†o xu·ªëng) l√† r·∫•t l·ªõn v√† c√≥ th·ªÉ v∆∞·ª£t qu√° gi·ªõi h·∫°n c·ªßa l∆∞·ª£ng d·ªØ li·ªáu m√† ta c√≥ th·ªÉ truy·ªÅn v√†o m·ªôt model call. V√¨ v·∫≠y, ta c·∫ßn **chia document th√†nh nhi·ªÅu chunk** c√≥ th·ªÉ qu·∫£n l√Ω ƒë∆∞·ª£c. Ta c√≥ th·ªÉ s·ª≠ d·ª•ng [text splitter](https://js.langchain.com/docs/modules/data_connection/document_transformers/):

```jsx
import { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";

const splitter = new RecursiveCharacterTextSplitter();

const loader = new CheerioWebBaseLoader(
  "https://docs.smith.langchain.com/user_guide"
);

const docs = await loader.load();

const splitDocs = await splitter.splitDocuments(docs);

console.log(splitDocs.length);
console.log(splitDocs[0].pageContent.length);
```

```jsx
49;
441;
```

Ti·∫øp theo, ta c·∫ßn index d·ªØ li·ªáu ƒë∆∞·ª£c c√†o xu·ªëng v√†o m·ªôt vector store. ƒê·ªÉ l√†m ƒë∆∞·ª£c vi·ªác n√†y, ta c·∫ßn th√™m m·ªôt v√†i component, ƒë√≥ l√† [**embedding model**](https://js.langchain.com/docs/modules/data_connection/text_embedding)¬†v√†¬†[**vectorstore**](https://js.langchain.com/docs/modules/data_connection/vectorstores).

```jsx
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings();
```

Gi·ªù ta c√≥ th·ªÉ d√πng embedding model n√†y ƒë·ªÉ nh·∫≠p d·ªØ li·ªáu t·ª´ document (d·ªØ li·ªáu crawl ƒë∆∞·ª£c) v√†o vectorstore. Ta s·∫Ω s·ª≠ d·ª•ng¬†[simple in-memory demo vectorstore](https://js.langchain.com/docs/integrations/vectorstores/memory) ƒë·ªÉ l√†m v√≠ d·ª•:

```jsx
import { MemoryVectorStore } from "langchain/vectorstores/memory";

const vectorstore = await MemoryVectorStore.fromDocuments(
  splitDocs,
  embeddings
);
```

LangChain vectorstore class s·∫Ω t·ª± ƒë·ªông t·∫°o ra c√°c raw document (index) b·∫±ng embeddings model.

Khi ta ƒë√£ c√≥ c√°c indexed data trong vectorstore, ta s·∫Ω t·∫°o ra m·ªôt retrieval chain. Chain n√†y s·∫Ω nh·∫≠n input l√† m·ªôt c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng, t√¨m ki·∫øm c√°c document li√™n quan trong vectorstore, sau ƒë√≥ truy·ªÅn c√¢u h·ªèi v√† document li√™n quan n√†y t·ªõi LLM ƒë·ªÉ n√≥ tr·∫£ l·ªùi c√¢u h·ªèi.

ƒê·∫ßu ti√™n, ta c√†i ƒë·∫∑t m·ªôt chain nh·∫≠n input l√† [c√¢u h·ªèi, retrieved documents] r·ªìi sinh ra c√¢u tr·∫£ l·ªùi

```jsx
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const prompt =
  ChatPromptTemplate.fromTemplate(`Answer the following question based only on the provided context:

<context>
{context}
</context>

Question: {input}`);

const documentChain = await createStuffDocumentsChain({
  llm: chatModel,
  prompt,
});
```

Ta c√≥ th·ªÉ ch·∫°y n√≥ b·∫±ng c√°ch truy·ªÅn tr·ª±c ti·∫øp **c√¢u h·ªèi** v√† **document** (ƒë√≥ng vai tr√≤ nh∆∞ b·ªëi c·∫£nh) v√†o `documentChain.invoke`:

```jsx
import { Document } from "@langchain/core/documents";

await documentChain.invoke({
  input: "what is LangSmith?",
  context: [
    new Document({
      pageContent:
        "LangSmith is a platform for building production-grade LLM applications.",
    }),
  ],
});
```

```jsx
 LangSmith is a platform for building production-grade Large Language Model (LLM) applications.
```

Tuy nhi√™n, ta mu·ªën c√°c document ƒëi qua Retriever m√† ta v·ª´a c√†i ƒë·∫∑t tr∆∞·ªõc v√¨ Retriever s·∫Ω l·ª±a ch·ªçn c√°c document ph√π h·ª£p nh·∫•t ƒë·ªÉ cho v√†o chain thay v√¨ cho t·∫•t c·∫£ document v√†o chain.

```jsx
import { createRetrievalChain } from "langchain/chains/retrieval";

const retriever = vectorstore.asRetriever();

const retrievalChain = await createRetrievalChain({
  combineDocsChain: documentChain,
  retriever,
});

const result = await retrievalChain.invoke({
  input: "what is LangSmith?",
});

console.log(result.answer);
```

```jsx
LangSmith is a tool developed by LangChain that is used for debugging and monitoring LLMs, chains, and agents in order to improve their performance and reliability for use in production.
```

Full source code
  ```jsx
  import { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";
  import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
  import { OpenAIEmbeddings } from "@langchain/openai";
  import { MemoryVectorStore } from "langchain/vectorstores/memory";
  import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
  import { ChatPromptTemplate } from "@langchain/core/prompts";
  import { createRetrievalChain } from "langchain/chains/retrieval";
  import { ChatOpenAI } from "@langchain/openai";

  const loader = new CheerioWebBaseLoader(
    "https://docs.smith.langchain.com/user_guide"
  );
  const splitter = new RecursiveCharacterTextSplitter();
  const embeddings = new OpenAIEmbeddings();
  const chatModel = new ChatOpenAI({});

  const docs = await loader.load();
  const splitDocs = await splitter.splitDocuments(docs);
  const vectorstore = await MemoryVectorStore.fromDocuments(
    splitDocs,
    embeddings
  );

  const prompt =
    ChatPromptTemplate.fromTemplate(`Answer the following question based only on the provided context:
  
  <context>
  {context}
  </context>
  
  Question: {input}`);

  const documentChain = await createStuffDocumentsChain({
    llm: chatModel,
    prompt,
  });

  const retriever = vectorstore.asRetriever();
  const retrievalChain = await createRetrievalChain({
    combineDocsChain: documentChain,
    retriever,
  });

  const result = await retrievalChain.invoke({
    input: "what is LangSmith?",
  });

  console.log(result.answer);
  ```

### 3.6. Conversational retrieval chain

Nh·ªØng g√¨ ta l√†m ·ªü tr√™n ch·ªâ gi√∫p ta tr·∫£ l·ªùi m·ªôt c√¢u h·ªèi duy nh·∫•t. ·ªû ph·∫ßn n√†y, ta s·∫Ω t·∫°o ra **chain m√† c√≥ th·ªÉ tr·∫£ l·ªùi nhi·ªÅu c√¢u h·ªèi li√™n ti·∫øp**.

Khi s·ª≠ d·ª•ng h√†m `createRetrievalChain`, ta c·∫ßn thay ƒë·ªïi 2 th·ª©:

1. Retriever kh√¥ng ch·ªâ d·ª±a v√†o input g·∫ßn nh·∫•t m√† c·∫ßn d·ª±a v√†o c·∫£ cu·ªôc tr√≤ chuy·ªán
   - Retriever c·ªßa ta ƒëang ch·ªâ ƒë∆∞a nh·ªØng document **li√™n quan t·ªõi input g·∫ßn nh·∫•t** v√†o chain
   - Ta mu·ªën ƒë∆∞a nh·ªØng document **li√™n quan t·ªõi c·∫£ cu·ªôc tr√≤ chuy·ªán**
   - V√¨ v·∫≠y, ta c·∫ßn LLM sinh ra cho ta m·ªôt search query. Serach query s·∫Ω gi√∫p ta c√≥ ƒë∆∞·ª£c m·ªôt retriever m·ªõi m√† c√≥ th·ªÉ l·ªçc nh·ªØng document li√™n quan t·ªõi c·∫£ cu·ªôc tr√≤ chuy·ªán.
2. The final LLM chain c≈©ng c·∫ßn quan t√¢m t·ªõi c·∫£ cu·ªôc tr√≤ chy·ªán
   - LLM c·ªßa ta ch·ªâ xem x√©t b·ªëi c·∫£nh v√† **input g·∫ßn nh·∫•t** ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi
   - Ta mu·ªën LLM xem x√©t b·ªëi c·∫£nh v√† **c·∫£ cu·ªôc tr√≤ truy·ªán** ƒë·ªÉ ƒë∆∞a ra c√¢u tr·∫£ l·ªùi

```jsx
import { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { createRetrievalChain } from "langchain/chains/retrieval";
import { ChatOpenAI } from "@langchain/openai";
import { createHistoryAwareRetriever } from "langchain/chains/history_aware_retriever";
import { MessagesPlaceholder } from "@langchain/core/prompts";
import { HumanMessage, AIMessage } from "@langchain/core/messages";

const loader = new CheerioWebBaseLoader(
  "https://docs.smith.langchain.com/user_guide"
);
const splitter = new RecursiveCharacterTextSplitter();
const embeddings = new OpenAIEmbeddings();
const chatModel = new ChatOpenAI({});

const docs = await loader.load();
const splitDocs = await splitter.splitDocuments(docs);
const vectorstore = await MemoryVectorStore.fromDocuments(
  splitDocs,
  embeddings
);
const retriever = vectorstore.asRetriever();

const historyAwarePrompt = ChatPromptTemplate.fromMessages([
  new MessagesPlaceholder("chat_history"),
  ["user", "{input}"],
  [
    "user",
    "Given the above conversation, generate a search query to look up in order to get information relevant to the conversation",
  ],
]);

const historyAwareRetrieverChain = await createHistoryAwareRetriever({
  llm: chatModel,
  retriever,
  rephrasePrompt: historyAwarePrompt,
});

const historyAwareRetrievalPrompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    "Answer the user's questions based on the below context:\n\n{context}",
  ],
  new MessagesPlaceholder("chat_history"),
  ["user", "{input}"],
]);

const historyAwareCombineDocsChain = await createStuffDocumentsChain({
  llm: chatModel,
  prompt: historyAwareRetrievalPrompt,
});

const conversationalRetrievalChain = await createRetrievalChain({
  retriever: historyAwareRetrieverChain,
  combineDocsChain: historyAwareCombineDocsChain,
});

const result2 = await conversationalRetrievalChain.invoke({
  chat_history: [
    new HumanMessage("Can LangSmith help test my LLM applications?"),
    new AIMessage("Yes!"),
  ],
  input: "tell me how",
});

console.log(result2.answer);
```

### 3.7. PDF loader chain

```jsx
import { PDFLoader } from "langchain/document_loaders/fs/pdf";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { OpenAIEmbeddings } from "@langchain/openai";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { createRetrievalChain } from "langchain/chains/retrieval";
import { StructuredOutputParser } from "langchain/output_parsers";

const splitter = new RecursiveCharacterTextSplitter();
const loader = new PDFLoader("public/pdf/invoice.pdf");
const embeddings = new OpenAIEmbeddings();
const chatModel = new ChatOpenAI({});

const docs = await loader.load();
const splitDocs = await splitter.splitDocuments(docs);
const vectorstore = await MemoryVectorStore.fromDocuments(
  splitDocs,
  embeddings
);

const parser = StructuredOutputParser.fromNamesAndDescriptions({
  total: "total amount of money in the invoice",
  tax: "total tax amount in the invoice",
});

const prompt =
  ChatPromptTemplate.fromTemplate(`Answer the following question based only on the provided context:

<context>
{context}
</context>

Generate the response based on this structured output:
{format_instructions}

Question: {input}`);

const documentChain = await createStuffDocumentsChain({
  llm: chatModel,
  prompt,
  outputParser: parser,
});

const retriever = vectorstore.asRetriever();
const retrievalChain = await createRetrievalChain({
  combineDocsChain: documentChain,
  retriever,
});

const result = await retrievalChain.invoke({
  input: "what is the total money of this invoice?",
  format_instructions: parser.getFormatInstructions(),
});

console.log(result.answer);
```
