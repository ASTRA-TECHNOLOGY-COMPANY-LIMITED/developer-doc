# 머신러닝 분류

## 원문 출처

[글 2: 머신 러닝 알고리즘 분류](https://machinelearningcoban.com/2016/12/27/categories/)

## 학습 방법을 기반으로 한 분류

### 지도 학습 - 감독 학습

![Untitled](Pha%CC%82n%20loa%CC%A3i%20Machine%20Learning%20fa49790c43b341888a84457f420855ae/Untitled.png)

- **이해하기 쉬운 정의**: 감독 학습은 "감독자"가 이미 알고있는 데이터에 대해 머신이 학습하는 것입니다.
    
    예를 들어, 개와 고양이의 많은 사진이 포함된 이미지 저장소가 있다면 감독자는 각 사진에 대한 레이블을 붙인 다음 머신에게 전달합니다.
    
- **정의**: 감독 학습은 새로운 입력 데이터에 대한 출력(결과)을 알려진 (입력, 결과) 쌍을 기반으로 예측하는 알고리즘입니다.
    - 이러한 데이터 쌍은 (데이터, 레이블)이라고도 불립니다.
    - 감독 학습은 가장 일반적인 그룹 중 하나입니다.
- **수학적 정의**
    
    ********************************지도 학습********************************은 $X = \{ x_1, x_2,...\}$ 및 해당하는 $Y = \{ y_1, y_2, ... \}$ 세트가 있을 때 각 $ \{ x_i, y_i \}$가 벡터인 경우입니다.
    
    이러한 데이터 쌍 $\{ x_i, y_i \}$를 훈련 데이터라고 합니다.
    
    훈련 데이터에서 $f(x)$ 함수를 생성하여 $X$의 각 요소를 $Y$로 매핑해야 합니다.
    
    따라서 새로운 $x$가 있을 때 우리는 그것의 레이블인 $y = f(x)$를 찾을 수 있습니다.
    
- **예시**
    - 예시 1: 손글씨 인식에서, 우리는 수천 명의 사람들에 의해 쓰여진 각 숫자의 이미지를 가지고 있습니다. 우리는 알고리즘에 각 이미지에 대한 숫자가 무엇인지 알려줍니다. 알고리즘은 모델을 만든 다음, 새로운 이미지를 받으면 해당 이미지에 어떤 숫자가 있는지 예측합니다.
- **************분류**************
    - **분류**: 입력 데이터의 레이블이 유한한 수의 그룹으로 나뉠 때 분류라고합니다.
        
        예: 이미지가 개, 고양이 또는 말인지 확인하기.
        
    - **회귀**: 레이블이 그룹으로 나누어지지 않고 특정 실제 값이 될 때 회귀입니다.
        
        예: 넓이 $x$ $m^2$를 가진 집, $y$ 침실 및 도시 중심에서의 거리 $z$ km의 **가격**은 얼마인가? 여기서 레이블은 집의 가격으로 실수입니다.
        
        최근에 Microsoft는 얼굴을 기반으로 성별과 나이를 예측하는 응용 프로그램을 출시했습니다. 성별을 예측하는 부분은 ****************************분류****************************이며 나이를 예측하는 부분은 ********************회귀********************입니다. (*알림: 나이 예측 부분도 현재 문제에서 나이를 음의 정수로 간주하지 않으면 **분류**로 볼 수 있습니다.*)

### 비지도 학습 - Unsupervised Learning

![Untitled](Pha%CC%82n%20loa%CC%A3i%20Machine%20Learning%20fa49790c43b341888a84457f420855ae/Untitled%201.png)

비지도 학습은 레이블이 지정되지 않은 데이터로 학습하는 것으로, 기계는 그 규칙을 스스로 파악해야 합니다.

- **정의**: 비지도 학습은 입력(X)만 있고 출력(Y 레이블)이 없는 학습이며, 입력만 있고 해당 출력을 모르고 계산합니다.

    비지도 학습 알고리즘은 데이터의 구조를 기반으로 특정 작업을 수행합니다.
    
    예: 클러스터링 또는 데이터의 차원을 축소하여 저장 및 계산을 용이하게 하는 차원 축소. 
    
    이러한 유형의 알고리즘은 Unsupervised learning로 불립니다. Supervised learning과 달리 각 입력 데이터에 대한 정확한 답을 모릅니다. 비유적으로, 우리가 학교에서 수업을 듣는 것과 같이 정확한 답을 가르쳐주는 교사가 없습니다.

- **수학적 정의**: 비지도 학습은 입력 데이터 $X$만 있고 해당하는 레이블 $Y$를 알지 못할 때 발생합니다.
- **분류**
    - **군집화 (Clustering)**: 전체 데이터 $X$를 각 그룹 간의 관련성에 따라 작은 그룹으로 분류하는 문제입니다.
        
        예: 종이 조각을 삼각형, 사각형, 원 등의 모양에 따라 분류.
        
    - **Association**: 주어진 많은 데이터를 기반으로 규칙을 발견하는 문제입니다.
        
        예:
        
        - 남성 고객이 청바지를 사면 벨트나 시계를 추가로 구매하는 경향이 있음.
        - Spider Man을 시청한 관객은 Bat Man을 더 자주 시청함.
        - 이를 기반으로 추천 시스템을 만듦.

### 반지도 학습 - Semi-Supervised Learning

- **정의**: 반지도 학습은 입력 데이터 $X$가 많지만 그 중 일부만 레이블이 지정된 문제입니다.

    이러한 문제는 위에서 언급한 두 그룹의 중간에 속합니다.
    
- **예시**: 산부인과 수술에 관한 사진이 있을 때 일부는 레이블이 부여될 수 있습니다.

    실제로 많은 기계 학습 문제가 이 그룹에 속하며, 레이블이 부여된 데이터 수집은 많은 시간과 비용이 소요됩니다. 일부 데이터는 전문가에 의해만 레이블이 지정될 수 있습니다(의료 이미지 등). 그러나 레이블이 없는 데이터는 인터넷에서 상대적으로 저렴하게 수집할 수 있습니다.

### 강화 학습 - Reinforcement Learning

- **정의**: 강화 학습은 시스템이 상황에 따라 행동을 결정하여 최대 이익을 얻도록 하는 문제입니다.

    현재 강화 학습은 주로 게임 이론에 응용되어 다음 수를 결정하기 위한 알고리즘을 개발하는 데 사용됩니다.
    
- **예시**
    
    **예시 1:** [AlphaGo가 바둑에서 인간을 이기는 것으로 유명](https://gogameguru.com/tag/deepmind-alphago-lee-sedol/). 바둑은 굉장히 복잡한 게임으로, 총 가능한 수는 약 $10^{761}$이며, 이는 체스의 $10^{120}$ 및 우주의 총 원자 수인 $10^{80}$보다 훨씬 많습니다. 따라서 알고리즘은 다양한 선택지 중 최적의 수를 선택해야 합니다. AlphaGo는 기본적으로 지도 학습 및 강화 학습 알고리즘을 포함합니다. 지도 학습에서는 인간이 서로 경기한 바둑 데이터가 사용되어 모델을 훈련시킵니다. 그러나 AlphaGo의 최종 목표는 인간처럼 게임을 하는 것이 아니라 인간을 이기는 것이므로 훈련 후에는 자체적으로 게임을 수천 번 자체 플레이하여 더 나은 수를 찾아냅니다. 이 부분은 강화 학습에 해당합니다. (자세한 내용은 [Google DeepMind's AlphaGo: How it works](https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/)에서 확인할 수 있습니다.)
    
    **예시 2:** [컴퓨터에게 슈퍼 마리오 게임을 가르치기](https://www.youtube.com/watch?v=qv6UVOQ0F44). 이는 컴퓨터에게 슈퍼 마리오 게임을 가르치는 흥미로운 프로그램입니다. 이 게임은 바둑보다 간단하며 특정 시점에서 플레이어는 소수의 버튼(이동, 점프, 쏘기)을 눌러야 하거나 버튼을 누를 필요가 없습니다. 동시에 알고리 즘의 응답도 더 간단하며 각 플레이에서 반복됩니다(특정 시점에 특정 위치에 고정된 장애물이 있음). 알고리즘의 입력은 현재 화면의 구성이며, 알고리즘의 작업은 그 입력에 대해 어떤 조합의 키를 눌러야 하는지 결정하는 것입니다. 이 훈련은 게임에서 얼마나 멀리 이동할 수 있는지에 대한 점수에 따라 진행되며, 이는 높을수록 더 많은 보상을 얻습니다(이 보상은 게임의 점수가 아닌 프로그래머가 만든 것입니다). 훈련을 통해 알고리즘은 최적의 방법을 찾아 게임에서 최대한 많은 점수를 얻을 수 있도록 합니다.

---

## 기능 기반 분류

알고리즘의 기능에 따라 두 번째 분류 방법이 있습니다. 이 섹션에서는 알고리즘을 나열하겠습니다. 구체적인 정보는 이 블로그의 다른 글에서 다룰 것입니다. 작성 중에 몇 가지 알고리즘을 추가 또는 삭제할 수 있습니다.

### **회귀 알고리즘**

1. [선형 회귀](https://machinelearningcoban.com/2016/12/28/linearregression/)
2. [로지스틱 회귀](https://machinelearningcoban.com/2017/01/27/logisticregression/#sigmoid-function)
3. 단계별 회귀

### **분류 알고리즘**

1. 선형 분류기
2. [서포트 벡터 머신 (SVM)](https://machinelearningcoban.com/2017/04/09/smv/)
3. [커널 SVM](https://machinelearningcoban.com/2017/04/22/kernelsmv/)
4. 희소 표현 기반 분류 (SRC)

### **인스턴스 기반 알고리즘**

1. [k-최근접 이웃 (kNN)](https://machinelearningcoban.com/2017/01/08/knn/)
2. 학습 벡터 양자화 (LVQ)

### **정규화 알고리즘**

1. 릿지 회귀
2. 최소 절대 수축 및 선택 연산자 (LASSO)
3. 최소 각도 회귀 (LARS)

### **베이지안 알고리즘**

1. 나이브 베이즈
2. 가우시안 나이브 베이즈

### **군집 알고리즘**

1. [k-평균 군집화](https://machinelearningcoban.com/2017/01/01/kmeans/)
2. k-중앙값
3. 기대 최대화 (EM)

### **인공 신경망 알고리즘**

1. [퍼셉트론](https://machinelearningcoban.com/2017/01/21/perceptron/)
2. [소프트맥스 회귀](https://machinelearningcoban.com/2017/02/17/softmax/)
3. [다층 퍼셉트론](https://machinelearningcoban.com/2017/02/24/mlp/)
4. [역전파](https://machinelearningcoban.com/2017/02/24/mlp/#-backpropagation)

### **차원 축소 알고리즘**

1. [주성분 분석 (PCA)](https://machinelearningcoban.com/2017/06/15/pca/)
2. [선형 판별 분석 (LDA)](https://machinelearningcoban.com/2017/06/30/lda/)

### **앙상블 알고리즘**

1. 부스팅
2. 아다부스트
3. 랜덤 포레스트

그리고 많은 다른 알고리즘이 있습니다.

---

## **참고 자료**

1. [머신 러닝 알고리즘 개요](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
2. [현대 머신 러닝 알고리즘 개요](https://ongxuanhong.wordpress.com/2015/10/22/diem-qua-cac-thuat-toan-machine-learning-hien-dai/)