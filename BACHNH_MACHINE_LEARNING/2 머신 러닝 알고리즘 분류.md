Dịch sang tiếng Hàn:

# 2. 머신 러닝 알고리즘 분류

## 글 출처

[글 2: 머신 러닝 알고리즘 분류](https://machinelearningcoban.com/2016/12/27/categories/)

## 학습 방법에 따른 분류

### 지도 학습 - Supervised Learning

- **정의**: 지도 학습은 미지의 입력 데이터(new input)에 대한 출력(outcome)을 알려진 입력과 결과(input, outcome) 쌍을 기반으로 예측하는 알고리즘입니다.
  - 이러한 데이터 쌍은 (data, label)이라고도 합니다.
  - 지도 학습은 가장 일반적인 그룹 중 하나입니다.
- **수학적 정의**
  **************\*\*\*\***************Supervised Learning**************\*\*\*\*************** 은 입력 데이터 집합 $X = \{ x_1, x_2,...\}$ 및 해당하는 결과 집합 $Y = \{ y_1, y_2, ... \}$을 가질 때, 각 $\{ x_i, y_i \}$가 하나의 벡터인 경우입니다.
  이러한 데이터 쌍 $\{ x_i, y_i \}$은 학습 데이터라고 합니다.
  학습 데이터를 통해 우리는 각 요소를 $X$에서 $Y$로 매핑하는 함수 $f(x)$를 생성해야 합니다.
  따라서 새로운 $x$가 주어지면 그것의 레이블을 $y = f(x)$로 찾을 수 있습니다.
- **예제**
  - 예제 1: 필적 문자 인식에서 우리는 여러 사람에 의해 작성된 각 숫자의 수천 개의 이미지를 가지고 있습니다. 이러한 이미지를 알고리즘에 제공하고 각 이미지가 어떤 숫자를 나타내는지를 알려줍니다. 알고리즘이 모델을 만들면, 즉 이미지를 입력으로 받고 숫자를 출력으로 내보낼 수 있으므로 새 이미지가 주어지면 그 이미지에 어떤 숫자가 포함되어 있는지 예측할 수 있습니다.
- ******\*\*******분류******\*\*******
  - **분류 (Classification)**: 입력 데이터의 레이블이 유한한 수의 그룹으로 나누어질 때 분류 문제로 간주됩니다.
    예: Gmail은 이메일이 스팸인지 아닌지를 판별합니다; 신용카드 회사는 고객이 빚을 상환할 가능성이 있는지를 판별합니다. 여기서 레이블은 "예" 또는 "아니오"로 나누어집니다.
  - **회귀 (Regression)**: 레이블이 몇 가지 구체적인 값을 가질 때 분류되지 않고 실제 숫자로 나타납니다.
    예: 집의 평방 미터, 침실 수, 도시 중심까지의 거리가 주어지면 집의 가격은 얼마인가요? 여기서 레이블은 집의 가격으로 실수 값입니다.
  최근에 Microsoft은 얼굴 인식을 기반으로 성별과 나이를 예측하는 응용 프로그램을 가지고 있습니다. 성별 예측은 ******\*\*******Classification******\*\*******에 속하며 나이 예측은 ********\*\*\*\*********Regression********\*\*\*\*********에 속합니다. (_참고로 나이 예측도 정수 값으로 150을 초과하지 않기 때문에 나이를 양의 정수로 간주하면 150개의 서로 다른 클래스가 있습니다.)_

### 비지도 학습 - Unsupervised Learning

- **정의**: 비지도 학습은 입력 (X)만 있고 출력 (Y)이 없는 학습 방법입니다. 우리는 입력만 가지고 있으며 해당 입력의 출력을 알지 못합니다. 비지도 학습 알고리즘은 데이터의 구조를 기반으로 작업을 수행합니다.
  이러한 유형의 알고리즘은 Unsupervised Learning이라고 불립니다.
- **수학적 정의**: 비지도 학습은 입력 데이터 $X$만 가지고 있으며 해당 레이블 $Y$를 모릅니다.
- **분류**
  - ****\*\*****클러스터링 (Clustering)****\*\*****: Clustering는 모든 데이터 $X$를 각 그룹 간의 관련성을 기반으로 작은 그룹으로 나누는 문제입니다.
    예: 삼각형, 사각형, 원과 같은 모양을 기반으로 종이 조각을 분류합니다.
  - **연관규칙 (Association)**: 연관규칙은 주어진 많은 데이터를 기반으로 규칙을 찾는 문제를 해결합니다.
    예: 남성 고객이 청바지를 구매하면 무조건 벨트나 시계를 사는 경향이 있습니다. 이러한 정보를 기반으로 추천 시스템을 개발합니다.

### 준지도 학습 - Semi-Supervised Learning

- **정의**: 준지도 학습은 입력 데이터 $X$를 대량으로 제공하지만 그 중 일부만 레이블이 지정된 문제입니다.
  이러한 문제는 위에서 언급한 두 그룹 사이에 위치합니다.
- **예제**: 어떤 분류에서 수술 이미지가 주어지면

이러한 이미지는 의학적으로 예상됩니다.

    실제로 데이터에 레이블을 지정하는 것은 시간이 많이 소요되고 비용이 많이 들기 때문에 많은 머신 러닝 문제가이 그룹에 속합니다. 많은 유형의 데이터는 심지어 전문가에 의해 레이블을 지정하는 것이 필요합니다(예: 의료 이미지).

### 강화 학습 - Reinforcement Learning

- **정의**: 강화 학습은 상황에 따라 행동을 자동으로 결정하여 최대 이익을 얻기 위해 시스템이 행동을 스스로 결정하는 문제입니다.
  현재 강화 학습은 주로 게임 이론에 적용되며 최고의 점수를 얻기 위해 다음 단계의 움직임을 결정하는 알고리즘을 개발합니다.
- **예제**
  **예제 1:** [알파고(AlphaGo)는 바둑에서 인간을 이긴 성과로 유명합니다](https://gogameguru.com/tag/deepmind-alphago-lee-sedol/). 바둑은 매우 복잡한 게임으로 약 $10^{761}$개의 가능한 움직임이 있으며 체스보다 더 복잡하며 우주의 총 원자 수는 약 $10^{80}$개입니다. 따라서 최적의 움직임을 선택하는 것은 불가능하며 기본적으로는 [IBM Deep Blue](<https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)>)와 같은 방식으로 알고리즘을 적용할 수 없습니다. 알파고는 Supervised learning 및 Reinforcement learning을 포함한 여러 알고리즘으로 구성됩니다. Supervised learning 부분에서는 인간들이 서로 경기한 바둑 게임 데이터를 사용하여 모델을 훈련합니다. 그러나 알파고의 최종 목표는 인간처럼 게임을 하는 것이 아니라 인간을 이기는 것이므로 모든 데이터를 학습한 후 알파고는 자체적으로 게임을 진행하며 수백만 개의 게임을 통해 더 나은 움직임을 찾습니다. 이 자체 게임 부분의 알고리즘은 강화 학습에 속합니다. (자세한 내용은 [Google DeepMind’s AlphaGo: How it works](https://www.tastehit.com/blog/google-deepmind-alphago-how-it-works/)에서 확인할 수 있습니다).
  **예제 2:** [마리오 게임을 위한 컴퓨터 훈련](https://www.youtube.com/watch?v=qv6UVOQ0F44). 이것은 컴퓨터가 마리오 게임을 하는 방법을 가르치는 흥미로운 프로그램입니다. 이 게임은 바둑보다 훨씬 간단하며 특정 시점에서 플레이어가 누를 버튼 (이동, 점프, 총)의 수가 적거나 전혀 없습니다. 또한 기계의 반응은 단순하며 특정 시점에서 고정된 위치에 장애물이 나타납니다. 알고리즘의 입력은 현재 화면의 렌더링이며 알고리즘의 임무는 해당 입력을 기반으로 누를 버튼의 조합을 결정하는 것입니다. 이 훈련은 게임에서 얼마나 먼 거리에 얼마나 빨리 이동했는지에 따라 점수를 부여하며 이 점수는 게임 점수가 아니라 프로그래머가 만든 것입니다. 훈련을 통해 알고리즘은 최적의 움직임을 찾아 점수를 최대화하며 최종 목표는 공주를 구하는 것입니다.

---

## 기능에 따른 분류

두 번째 분류 방법은 알고리즘의 기능에 따라 나누는 것입니다. 이 섹션에서는 알고리즘을 나열하기만 하고 구체적인 정보는 이 블로그의 다른 글에서 제공됩니다. 글을 작성하는 과정에서 일부 알고리즘을 추가하거나 제거할 수 있습니다.

### 회귀 알고리즘 - Regression Algorithms

1. [선형 회귀](https://machinelearningcoban.com/2016/12/28/linearregression/)
2. [로지스틱 회귀](https://machinelearningcoban.com/2017/01/27/logisticregression/#sigmoid-function)
3. 단계별 회귀 (Stepwise Regression)

### 분류 알고리즘 - Classification Algorithms

1. 선형 분류기 (Linear Classifier)
2. [서포트 벡터 머신 (SVM)](https://machinelearningcoban.com/2017/04/09/smv/)
3. [커널 서포트 벡터 머신 (Kernel SVM)](https://machinelearningcoban.com/2017/04/22/kernelsmv/)
4. 희소 표현 기반 분류 (Sparse Representation-based Classification, SRC)

### 인스턴스 기반 알고리즘 - Instance-based Algorithms

1. [k-최근접 이웃 (k-Nearest Neighbor, kNN)](https://machinelearningcoban.com/2017/01/08

/knn/) 2. 학습 벡터 양자화 (Learning Vector Quantization, LVQ)

### 정규화 알고리즘 - Regularization Algorithms

1. 릿지 회귀 (Ridge Regression)
2. 최소 절대 축소 및 선택 연산자 (Least Absolute Shrinkage and Selection Operator, LASSO)
3. 최소 각도 회귀 (Least-Angle Regression, LARS)

### 베이지안 알고리즘 - Bayesian Algorithms

1. 나이브 베이즈 (Naive Bayes)
2. 가우시안 나이브 베이즈 (Gaussian Naive Bayes)

### 클러스터링 알고리즘 - Clustering Algorithms

1. [k-평균 클러스터링](https://machinelearningcoban.com/2017/01/01/kmeans/)
2. k-중심 클러스터링 (k-Medians)
3. 기대 최대화 (Expectation Maximization, EM)

### 인공 신경망 알고리즘 - Artificial Neural Network Algorithms

1. 퍼셉트론 (Perceptron)
2. 소프트맥스 회귀 (Softmax Regression)
3. 다층 퍼셉트론 (Multi-layer Perceptron, MLP)
4. 역전파 (Back-Propagation)

### 차원 축소 알고리즘 - Dimensionality Reduction Algorithms

1. 주성분 분석 (Principal Component Analysis, PCA)
2. 선형 판별 분석 (Linear Discriminant Analysis, LDA)

### 앙상블 알고리즘 - Ensemble Algorithms

1. 부스팅 (Boosting)
2. 에이다부스트 (AdaBoost)
3. 랜덤 포레스트 (Random Forest)

그리고 더 많은 다른 알고리즘이 있습니다.

---

## 참고 자료

1. [머신 러닝 알고리즘 개요](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/)
2. [현대 머신 러닝 알고리즘 요약](https://ongxuanhong.wordpress.com/2015/10/22/diem-qua-cac-thuat-toan-machine-learning-hien-dai/)
