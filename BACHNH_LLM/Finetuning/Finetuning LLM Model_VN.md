# Finetuning LLM Model

## 1. Transfer learning

**Transfer learning (chuyá»ƒn giao tri thá»©c)** lÃ  viá»‡c model táº­n dá»¥ng tri thá»©c cá»§a má»™t pre-trained model khÃ¡c nháº±m gia tÄƒng hiá»‡u quáº£ cho model.

NhÆ° ta Ä‘Ã£ biáº¿t, trong CNN:

- Convolutional Layer cÃ³ tÃ¡c dá»¥ng láº¥y ra nhá»¯ng Ä‘áº·c trÆ°ng cá»§a áº£nh. Qua tá»«ng lá»›p, Model sáº½ há»c Ä‘Æ°á»£c cÃ¡c chi tiáº¿t khÃ¡c nhau. (Äiá»ƒm â†’ ÄÆ°á»ng tháº³ng â†’ MÅ©i, tai,â€¦ â†’ KhuÃ´n máº·t)
- Sau Ä‘Ã³ Ä‘i vÃ o Fully Connected Layer Ä‘á»ƒ giáº£m chiá»u dá»¯ liá»‡u,â€¦

![image.png](images/image.png)

Váº­y ta cÃ³ thá»ƒ sá»­ dá»¥ng pháº§n Convolutional Network cá»§a pre-trained model (nhá»¯ng Conv Layer vÃ  Pool Layer) cho bÃ i toÃ¡n cá»§a chÃºng ta. QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c gá»i lÃ  **Transfer learning**.

![Untitled](images/Untitled.png)

Qua biá»ƒu Ä‘á»“ trÃªn, cÃ³ thá»ƒ nhÃ¬n tháº¥y 3 Æ°u Ä‘iá»ƒm cá»§a transfer learning:

- Performance khá»Ÿi Ä‘áº§u tá»‘t hÆ¡n
- Tá»‘c Ä‘á»™ gia tÄƒng performance tá»‘t hÆ¡n
- ÄÆ°á»ng tiá»‡m cáº­n cá»§a Ä‘á»™ chÃ­nh xÃ¡c tá»‘i Æ°u cao hÆ¡n (higher asymptote).

CÃ³ 2 loáº¡i transfer learning:

- **Feature Extractor**: ConvNet cá»§a pre-trained model cÃ³ output lÃ  cÃ¡c Ä‘áº·c Ä‘iá»ƒm áº£nh (tai nhÆ° nÃ o, mÅ©i ra sao,â€¦). Giá» cÃ¡c Ä‘áº·c Ä‘iá»ƒm Ä‘Ã³ sáº½ trá»Ÿ thÃ nh input cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh linear classifier (linearÂ [SVM](https://machinelearningcoban.com/2017/04/09/smv/), softmax classifier,..)  (linear regression hay logistic regression)
    - Hiá»ƒu Ä‘Æ¡n giáº£n lÃ  láº¥y ConvNet ná»‘i vá»›i Output layer, trong Ä‘Ã³ Activation Function á»Ÿ output layer cÃ³ thá»ƒ lÃ  softmax, logistic,â€¦
- **Fine tuning**: Sau khi láº¥y ra cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a áº£nh báº±ng viá»‡c sá»­ dá»¥ng ConvNet cá»§a pre-trained model, thÃ¬ ta sáº½ coi Ä‘Ã¢y lÃ  input cá»§a 1 CNN má»›i báº±ng cÃ¡ch thÃªm cÃ¡c ConvNet vÃ  Fully Connected layer. LÃ½ do lÃ  ConvNet cá»§a VGGFace 2 model cÃ³ thá»ƒ láº¥y ra Ä‘Æ°á»£c cÃ¡c thuá»™c tÃ­nh cá»§a máº·t ngÆ°á»i nÃ³i chung nhÆ°ng ngÆ°á»i Viá»‡t Nam cÃ³ nhÆ°ng Ä‘áº·c tÃ­nh khÃ¡c nÃªn cáº§n thÃªm 1 sá»‘ Convnet má»›i Ä‘á»ƒ há»c thÃªm cÃ¡c thuá»™c tÃ­nh cá»§a ngÆ°á»i Viá»‡t Nam.
    - Hiá»ƒu Ä‘Æ¡n giáº£n lÃ  láº¥y ConvNet ná»‘i vÃ o má»™t ConvNet khÃ¡c cá»§a riÃªng ta Ä‘á»ƒ train cho nhá»¯ng Ä‘áº·c Ä‘iá»ƒm riÃªng biá»‡t.

### 1.1. Feature Extractor

Ta chá»‰ giá»¯ láº¡i pháº§n ConvNet trong CNN vÃ  bá» Ä‘i FCs. Sau Ä‘Ã³ dÃ¹ng output cá»§a ConvNet cÃ²n láº¡i Ä‘á»ƒ lÃ m input cho **mÃ´ hÃ¬nh Logistic Regression vá»›i nhiá»u output**.

![BÃªn trÃ¡i lÃ  mÃ´ hÃ¬nh VGG16, bÃªn pháº£i lÃ  mÃ´ hÃ¬nh VGG16 chá»‰ bao gá»“m ConvNet (bá» Fully conencted layer)](images/Untitled%201.png)

BÃªn trÃ¡i lÃ  mÃ´ hÃ¬nh VGG16, bÃªn pháº£i lÃ  mÃ´ hÃ¬nh VGG16 chá»‰ bao gá»“m ConvNet (bá» Fully conencted layer)

MÃ´ hÃ¬nhÂ **logistic regression vá»›i nhiá»u output**Â cÃ³ 2 dáº¡ng:

1. **Dáº¡ng thá»© nháº¥t**Â lÃ  má»™t neural network, khÃ´ng cÃ³ hidden layer, hÃ m activation á»Ÿ output layer lÃ Â [softmax function](https://nttuan8.com/bai-7-gioi-thieu-keras-va-bai-toan-phan-loai-anh/#Xay_dung_model), loss function lÃ  hÃ mÂ [categorical-cross entropy](https://nttuan8.com/bai-7-gioi-thieu-keras-va-bai-toan-phan-loai-anh/#Loss_function), giá»‘ng nhÆ° bÃ iÂ [phÃ¢n loáº¡i áº£nh](https://nttuan8.com/bai-7-gioi-thieu-keras-va-bai-toan-phan-loai-anh/).
    
    ![Untitled](images/Untitled%202.png)
    
2. **Dáº¡ng thá»© hai**Â giá»‘ng nhÆ° bÃ i logistic regression, tá»©c lÃ  model chá»‰ phÃ¢n loáº¡i 2 class. Má»—i láº§n ta sáº½ phÃ¢n loáº¡i 1 class vá»›i táº¥t cáº£ cÃ¡c class cÃ²n láº¡i.
    
    ![Untitled](images/Untitled%203.png)
    

### 1.2. Fine tuning

Ta chá»‰ giá»¯ láº¡i pháº§n ConvNet trong CNN vÃ  bá» Ä‘i FCs. Sau Ä‘Ã³ thÃªm cÃ¡c Fully Connected layer má»›i vÃ o output cá»§a ConvNet.

![Untitled](images/Untitled%204.png)

Khi train model, ta chia lÃ m 2 giai Ä‘oáº¡n:

**Giai Ä‘oáº¡n 1**: VÃ¬ cÃ¡c fully connected layer ta má»›i thÃªm vÃ o cÃ³ cÃ¡c há»‡ sá»‘ Ä‘Æ°á»£c khá»Ÿi táº¡o ngáº«u nhiÃªn tuy nhiÃªn cÃ¡c layer trong ConvNet cá»§a pre-trained model Ä‘Ã£ Ä‘Æ°á»£c train vá»›i ImageNet dataset nÃªn ta sáº½ khÃ´ng train (Ä‘Ã³ng bÄƒng/freeze) trÃªn cÃ¡c layer trong ConvNet cá»§a model VGG16. Sau khoáº£ng 20-30 epoch thÃ¬ cÃ¡c há»‡ sá»‘ á»Ÿ cÃ¡c layer má»›i Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« dá»¯ liá»‡u thÃ¬ ta chuyá»ƒn sang giai Ä‘oáº¡n 2.

(Äá»c thÃªm vá» Epoch táº¡i Ä‘Ã¢y [**Deep Learning Crash Course for Beginners**](https://www.notion.so/Deep-Learning-Crash-Course-for-Beginners-8c01dd2ad1834f7491025125d5085efe?pvs=21).)

![Untitled](images/Untitled%205.png)

**Giai Ä‘oáº¡n 2**: Ta sáº½ unfreeze cÃ¡c layer trÃªn ConvNet cá»§a pre-trained model vÃ  train trÃªn cÃ¡c layer cá»§a ConvNet cá»§a pre-trained model vÃ  cÃ¡c layer má»›i. Báº¡n cÃ³ thá»ƒ unfreeze táº¥t cáº£ cÃ¡c layer trong ConvNet cá»§a VGG16 hoáº·c chá»‰ unfreeze má»™t vÃ i layer cuá»‘i tÃ¹y vÃ o thá»i gian vÃ  GPU báº¡n cÃ³.

![Untitled](images/Untitled%206.png)

<aside>
ğŸ’¡ **Nháº­n xÃ©t**

Accuracy cá»§a fine-tuning tá»‘t hÆ¡n so vá»›i feature extractor tuy nhiÃªn thá»i gian train cá»§a fine-tuning cÅ©ng lÃ¢u hÆ¡n ráº¥t nhiá»u. 

Giáº£i thÃ­ch Ä‘Æ¡n giáº£n thÃ¬ feature extractor chá»‰ láº¥y ra Ä‘áº·c Ä‘iá»ƒm chung chung tá»« pre-trained model cá»§a ImageNet dataset cho cÃ¡c data cá»§a ta, nÃªn khÃ´ng Ä‘Æ°á»£c chÃ­nh xÃ¡c láº¯m. 

Tuy nhiÃªn á»Ÿ pháº§n fine-tuning ta thÃªm cÃ¡c layer má»›i, cÅ©ng nhÆ° train láº¡i 1 sá»‘ layer á»Ÿ trong ConvNet cá»§a VGG16 nÃªn model giá» há»c Ä‘Æ°á»£c cÃ¡c thuá»™c tÃ­nh, Ä‘áº·c Ä‘iá»ƒm cá»§a cÃ¡c data cá»§a ta nÃªn Ä‘á»™ chÃ­nh xÃ¡c tá»‘t hÆ¡n.

</aside>

### 1.3. Khi nÃ o nÃªn dÃ¹ng transfer learning?

CÃ³ 2 yáº¿u tá»‘ quan trá»ng nháº¥t Ä‘á»ƒ dÃ¹ng transfer learning Ä‘Ã³ lÃ  

- KÃ­ch thÆ°á»›c cá»§a dá»¯ liá»‡u báº¡n cÃ³
- Sá»± tÆ°Æ¡ng Ä‘á»“ng cá»§a dá»¯ liá»‡u giá»¯a mÃ´ hÃ¬nh báº¡n cáº§n train vÃ  pre-trained model

CÃ¡c trÆ°á»ng há»£p ta cáº§n cÃ¢n nháº¯c:

- **Dá»¯ liá»‡u nhá» vÃ  tÆ°Æ¡ng tá»± vá»›i dá»¯ liá»‡u á»Ÿ pre-trained model â†’ Feature Extractor:** VÃ¬ dá»¯ liá»‡u nhá» nÃªn náº¿u dÃ¹ng fine-tuning thÃ¬ model sáº½ bá»‹ overfitting. HÆ¡n ná»¯a lÃ  dá»¯ liá»‡u tÆ°Æ¡ng tá»± nhau nÃªn lÃ  ConvNet cá»§a pre-trained model cÅ©ng láº¥y ra cÃ¡c Ä‘áº·c Ä‘iá»ƒm á»Ÿ dá»¯ liá»‡u cá»§a chÃºng ta. Do Ä‘Ã³ nÃªn dÃ¹ng feature extractor.
- **Dá»¯ liá»‡u lá»›n vÃ  tÆ°Æ¡ng tá»± vá»›i dá»¯ liá»‡u á»Ÿ pre-trained model â†’ Fine-tuning:** Giá» cÃ³ nhiá»u dá»¯ liá»‡u ta khÃ´ng sá»£ overfitting do Ä‘Ã³ nÃªn dÃ¹ng fine-tuning.
- **Dá»¯ liá»‡u nhá» nhÆ°ng khÃ¡c vá»›i dá»¯ liá»‡u á»Ÿ pre-trained model:** VÃ¬ dá»¯ liá»‡u nhá» nÃªn ta lÃªn dÃ¹ng feature extractor Ä‘á»ƒ trÃ¡nh overfitting. Tuy nhiÃªn do dá»¯ liá»‡u ta cÃ³ vÃ  dá»¯ liá»‡u á»Ÿ pre-trained model khÃ¡c nhau, nÃªn khÃ´ng nÃªn dÃ¹ng feature extractor vá»›i toÃ n bá»™ ConvNet cá»§a pre-trained model mÃ  chá»‰ dÃ¹ng cÃ¡c layer Ä‘áº§u. LÃ½ do lÃ  vÃ¬ cÃ¡c layer á»Ÿ phÃ­a trÆ°á»›c sáº½ há»c cÃ¡c Ä‘áº·c Ä‘iá»ƒm chung chung hÆ¡n (cáº¡nh, gÃ³c,â€¦), cÃ²n cÃ¡c layer phÃ­a sau trong ConvNet sáº½ há»c cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»¥ thá»ƒ hÆ¡n trong dataset (vÃ­ dá»¥ máº¯t, mÅ©i,..).
- **Dá»¯ liá»‡u báº¡n cÃ³ lá»›n vÃ  khÃ¡c vá»›i dá»¯ liá»‡u á»Ÿ pre-trained model:** Ta cÃ³ thá»ƒ train model tá»« Ä‘áº§u, tuy nhiÃªn sáº½ tá»‘t hÆ¡n náº¿u ta khá»Ÿi táº¡o cÃ¡c giÃ¡ trá»‹ weight cá»§a model vá»›i giÃ¡ trá»‹ cá»§a pre-trained model vÃ  sau Ä‘Ã³ train bÃ¬nh thÆ°á»ng.

**LÆ°u Ã½**

- VÃ¬ pre-trained model Ä‘Ã£ Ä‘Æ°á»£c train vá»›i kÃ­ch thÆ°á»›c áº£nh cá»‘ Ä‘á»‹nh, nÃªn khi dÃ¹ng pre-trained model ta cáº§n resize láº¡i áº£nh cÃ³ kÃ­ch áº£nh báº±ng kÃ­ch thÆ°á»›c mÃ  ConvNet cá»§a pre-trained model yÃªu cáº§u.
- Há»‡ sá»‘ learning rate cá»§a ConvNet cá»§a pre-trained model nÃªn Ä‘Æ°á»£c Ä‘áº·t vá»›i giÃ¡ trá»‹ nhá» vÃ¬ nÃ³ Ä‘Ã£ Ä‘Æ°á»£c há»c á»Ÿ pre-trained model nÃªn Ã­t cáº§n cáº­p nháº­t hÆ¡n so vá»›i cÃ¡c layer má»›i thÃªm.

## 2. Data augmentation

NgoÃ i transfer learning, cÃ³ má»™t kÄ© thuáº­t ná»¯a giáº£i quyáº¿t váº¥n Ä‘á» cÃ³ Ã­t dá»¯ liá»‡u cho viá»‡c training model, Ä‘Ã³ lÃ  data augmentation. Augmentation lÃ  kÄ© thuáº­t táº¡o ra dá»¯ liá»‡u training tá»« dá»¯ liá»‡u mÃ  ta Ä‘ang cÃ³. CÃ¹ng xem má»™t sá»‘ kÄ© thuáº­t augmentation phá»• biáº¿n vá»›i áº£nh nhÃ©

**Flip**: Láº­t ngÆ°á»£c áº£nh theo chiá»u dá»c hoáº·c chiá»u ngang

![https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/flip.png?resize=576%2C316&ssl=1](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/flip.png?resize=576%2C316&ssl=1)

**Rotation**: Quay áº£nh theo nhiá»u gÃ³c khÃ¡c nhau

![https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/rotate.png?resize=561%2C299&ssl=1](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/rotate.png?resize=561%2C299&ssl=1)

**Scale**: PhÃ³ng to hoáº·c thu nhá» áº£nh

![https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/scale.png?resize=568%2C290&ssl=1](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/scale.png?resize=568%2C290&ssl=1)

**Crop**: Cáº¯t má»™t vÃ¹ng áº£nh sau Ä‘Ã³ resize vÃ¹ng áº£nh Ä‘áº¥y vá» kÃ­ch thÆ°á»›c áº£nh ban Ä‘áº§u

![https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/scale-1.png?resize=568%2C290&ssl=1](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/scale-1.png?resize=568%2C290&ssl=1)

**Translation**: dá»‹ch chuyá»ƒn áº£nh theo chiá»u x, y.

![https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/translate.png?resize=548%2C281&ssl=1](https://i0.wp.com/nttuan8.com/wp-content/uploads/2019/04/translate.png?resize=548%2C281&ssl=1)

Tuy nhiÃªn khi rotate hoáº·c translation thÃ¬ áº£nh bá»‹ nhá»¯ng khoáº£ng Ä‘en mÃ  thÆ°á»ng áº£nh thá»±c táº¿ khÃ´ng cÃ³ cÃ¡c khoáº£ng Ä‘en Ä‘áº¥y nÃªn cÃ³ má»™t sá»‘ cÃ¡ch Ä‘á»ƒ xá»­ lÃ½ nhÆ°: láº¥y giÃ¡ trá»‹ tá»« cáº¡nh cá»§a áº£nh má»›i Ä‘á»ƒ cho cÃ¡c pixel bá»‹ Ä‘en, gÃ¡n cÃ¡c giÃ¡ trá»‹ Ä‘en báº±ng giÃ¡ trá»‹ cá»§a áº£nh Ä‘á»‘i xá»©ng qua cáº¡nh,â€¦

NÃªn Ã¡p dá»¥ng kiá»ƒu augmentation nÃ o thÃ¬ tÃ¹y thuá»™c vÃ o ngá»¯ nghÄ©a cá»§a áº£nh trong bÃ i toÃ¡n báº¡n Ä‘ang giáº£i quyáº¿t.